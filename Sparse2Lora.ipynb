{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhuWJXn7X7-Z",
        "outputId": "7fd9d5f8-c160-4b14-b324-0401a362a7b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sparsegpt'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 37 (delta 18), reused 8 (delta 8), pack-reused 11\u001b[K\n",
            "Receiving objects: 100% (37/37), 21.78 KiB | 5.45 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Copyright 2023 Ontocord.AI, Apache 2 License\n",
        "# Create Use sparsification on a specific data distribution, and SVD to create Loras from sparsified network.\n",
        "\n",
        "!git clone https://github.com/IST-DASLab/sparsegpt\n",
        "\n",
        "\n",
        "txt = \"\"\"Abraham Lincoln (/ˈlɪŋkən/ LINK-ən; February 12, 1809 – April 15, 1865) was an American lawyer, politician, and statesman who served as the 16th president of the United States from 1861 until his assassination in 1865. Lincoln led the Union through the American Civil War to defend the nation as a constitutional union and succeeded in abolishing slavery, bolstering the federal government, and modernizing the U.S. economy.\n",
        "\n",
        "Lincoln was born into poverty in a log cabin in Kentucky and was raised on the frontier, primarily in Indiana. He was self-educated and became a lawyer, Whig Party leader, Illinois state legislator, and U.S. Congressman from Illinois. In 1849, he returned to his successful law practice in Springfield, Illinois. In 1854, he was angered by the Kansas–Nebraska Act, which opened the territories to slavery, and he re-entered politics. He soon became a leader of the new Republican Party. He reached a national audience in the 1858 Senate campaign debates against Stephen A. Douglas. Lincoln ran for president in 1860, sweeping the North to gain victory. Pro-slavery elements in the South viewed his election as a threat to slavery, and Southern states began seceding from the nation. During this time, the newly formed Confederate States of America began seizing federal military bases in the south. Just over one month after Lincoln assumed the presidency, the Confederate States attacked Fort Sumter, a U.S. fort in South Carolina. Following the bombardment, Lincoln mobilized forces to suppress the rebellion and restore the union.\n",
        "\n",
        "\n",
        "Marriage and children\n",
        "\n",
        "Lincoln had pledged in 1846 to serve only one term in the House. Realizing Clay was unlikely to win the presidency, he supported General Zachary Taylor for the Whig nomination in the 1848 presidential election.[85] Taylor won and Lincoln hoped in vain to be appointed Commissioner of the General Land Office.[86] The administration offered to appoint him secretary or governor of the Oregon Territory as consolation.[87] This distant territory was a Democratic stronghold, and acceptance of the post would have disrupted his legal and political career in Illinois, so he declined and resumed his law practice.[88]\n",
        "\n",
        "Lincoln's second child was named\"\"\"\n",
        "\n",
        "try:\n",
        "  import accelerate, bitsandbytes\n",
        "  from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "except:\n",
        "  !pip install -q transformers accelerate bitsandbytes\n",
        "  !pip install -q datasets\n",
        "  !pip install -q sentencepiece\n",
        "  !pip install -q zstandard\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibVz6SUDbNRT",
        "outputId": "6efed1c5-5cb7-4b59-efec-88683c173ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sparsegpt/datautils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile sparsegpt/datautils.py\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, LlamaTokenizer\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.random.manual_seed(seed)\n",
        "\n",
        "def get_tokenizer(model):\n",
        "    if \"llama\" in model.lower():\n",
        "        tokenizer = LlamaTokenizer.from_pretrained(model, use_fast=False)\n",
        "        # fix for transformer 4.28.0.dev0 compatibility\n",
        "        if tokenizer.bos_token_id != 1 or tokenizer.eos_token_id != 2:\n",
        "            try:\n",
        "                tokenizer.bos_token_id = 1\n",
        "                tokenizer.eos_token_id = 2\n",
        "            except AttributeError:\n",
        "                pass\n",
        "    else:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model, use_fast=False)\n",
        "    return tokenizer\n",
        "\n",
        "def get_wikitext2(nsamples, seed, seqlen, model, tokenizer):\n",
        "\n",
        "    traindata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train')\n",
        "    testdata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
        "\n",
        "    trainenc = tokenizer(\" \".join(traindata['text']), return_tensors='pt')\n",
        "    testenc = tokenizer(\"\\n\\n\".join(testdata['text']), return_tensors='pt')\n",
        "\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in range(nsamples):\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "    return trainloader, testenc\n",
        "\n",
        "def get_ptb(nsamples, seed, seqlen, model, tokenizer):\n",
        "    traindata = load_dataset('ptb_text_only', 'penn_treebank', split='train')\n",
        "    testdata = load_dataset('ptb_text_only', 'penn_treebank', split='test')\n",
        "\n",
        "    trainenc = tokenizer(\" \".join(traindata['sentence']), return_tensors='pt')\n",
        "    testenc = tokenizer(\" \".join(testdata['sentence']), return_tensors='pt')\n",
        "\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in range(nsamples):\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "    return trainloader, testenc\n",
        "\n",
        "import tqdm\n",
        "def get_c4(nsamples, seed, seqlen, model, tokenizer):\n",
        "    traindata = load_dataset(\n",
        "        'allenai/c4', 'allenai--c4', data_files={'train': 'en/c4-train.00000-of-01024.json.gz'}, split='train'\n",
        "    )\n",
        "    valdata = load_dataset(\n",
        "        'allenai/c4', 'allenai--c4', data_files={'validation': 'en/c4-validation.00000-of-00008.json.gz'}, split='validation'\n",
        "    )\n",
        "\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in range(nsamples):\n",
        "        while True:\n",
        "            i = random.randint(0, len(traindata) - 1)\n",
        "            trainenc = tokenizer(traindata[i]['text'], return_tensors='pt')\n",
        "            if trainenc.input_ids.shape[1] > seqlen:\n",
        "                break\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "\n",
        "    valenc = tokenizer(' '.join(valdata[:1100]['text']), return_tensors='pt')\n",
        "    valenc = valenc.input_ids[:, :(256 * seqlen)]\n",
        "\n",
        "    class TokenizerWrapper:\n",
        "        def __init__(self, input_ids):\n",
        "            self.input_ids = input_ids\n",
        "    valenc = TokenizerWrapper(valenc)\n",
        "\n",
        "    return trainloader, valenc\n",
        "\n",
        "\n",
        "def get_generic(nsamples, seed, seqlen, model, tokenizer, dataset_name, train, validation):\n",
        "\n",
        "    traindata = load_dataset(\n",
        "        dataset_name, split=train,\n",
        "    )\n",
        "    valdata = load_dataset(\n",
        "        dataset_name, split=validation,\n",
        "    )\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in tqdm.tqdm(range(nsamples)):\n",
        "        while True:\n",
        "            i = random.randint(0, len(traindata) - 1)\n",
        "            trainenc = tokenizer(traindata[i]['text'], return_tensors='pt')\n",
        "            if trainenc.input_ids.shape[1] > seqlen:\n",
        "                break\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "\n",
        "    valenc = tokenizer(' '.join(valdata[:1100]['text']), return_tensors='pt')\n",
        "    valenc = valenc.input_ids[:, :(256 * seqlen)]\n",
        "\n",
        "    class TokenizerWrapper:\n",
        "        def __init__(self, input_ids):\n",
        "            self.input_ids = input_ids\n",
        "    valenc = TokenizerWrapper(valenc)\n",
        "\n",
        "    return trainloader, valenc\n",
        "\n",
        "def get_loaders(name, nsamples=128, seed=0, seqlen=2048, model=''):\n",
        "    tokenizer = get_tokenizer(model)\n",
        "    if 'wikitext2' in name:\n",
        "        return get_wikitext2(nsamples, seed, seqlen, model, tokenizer)\n",
        "    elif 'ptb' in name:\n",
        "        return get_ptb(nsamples, seed, seqlen, model, tokenizer)\n",
        "    elif 'c4' in name:\n",
        "        return get_c4(nsamples, seed, seqlen, model, tokenizer)\n",
        "    else:\n",
        "        name, train, validiation = name.split(\",\")\n",
        "        return get_generic(nsamples, seed, seqlen, model, tokenizer, name, train, validiation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d3oKaq9mos6",
        "outputId": "22224440-7e2a-4f17-e51e-b361ac8641a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sparsegpt/llama.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile sparsegpt/llama.py\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from sparsegpt import *\n",
        "from modelutils import *\n",
        "from quant import *\n",
        "\n",
        "try:\n",
        "    import wandb\n",
        "    has_wandb = True\n",
        "except:\n",
        "    has_wandb = False\n",
        "\n",
        "\n",
        "def get_llama(model):\n",
        "    import torch\n",
        "    def skip(*args, **kwargs):\n",
        "        pass\n",
        "    torch.nn.init.kaiming_uniform_ = skip\n",
        "    torch.nn.init.uniform_ = skip\n",
        "    torch.nn.init.normal_ = skip\n",
        "    from transformers import LlamaForCausalLM\n",
        "    model = LlamaForCausalLM.from_pretrained(model, torch_dtype='auto')\n",
        "    model.seqlen = 2048\n",
        "    return model\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def llama_sequential(model, dataloader, dev):\n",
        "    print(\"Starting...\")\n",
        "\n",
        "    use_cache = model.config.use_cache\n",
        "    model.config.use_cache = False\n",
        "    layers = model.model.layers\n",
        "\n",
        "    model.model.embed_tokens = model.model.embed_tokens.to(dev)\n",
        "    model.model.norm = model.model.norm.to(dev)\n",
        "    layers[0] = layers[0].to(dev)\n",
        "\n",
        "    dtype = next(iter(model.parameters())).dtype\n",
        "    inps = torch.zeros(\n",
        "        (args.nsamples, model.seqlen, model.config.hidden_size), dtype=dtype, device=dev\n",
        "    )\n",
        "    cache = {\"i\": 0, \"attention_mask\": None}\n",
        "\n",
        "    class Catcher(nn.Module):\n",
        "        def __init__(self, module):\n",
        "            super().__init__()\n",
        "            self.module = module\n",
        "\n",
        "        def forward(self, inp, **kwargs):\n",
        "            inps[cache[\"i\"]] = inp\n",
        "            cache[\"i\"] += 1\n",
        "            cache[\"attention_mask\"] = kwargs[\"attention_mask\"]\n",
        "            raise ValueError\n",
        "\n",
        "    layers[0] = Catcher(layers[0])\n",
        "    for batch in dataloader:\n",
        "        try:\n",
        "            model(batch[0].to(dev))\n",
        "        except ValueError:\n",
        "            pass\n",
        "    layers[0] = layers[0].module\n",
        "\n",
        "    layers[0] = layers[0].cpu()\n",
        "    model.model.embed_tokens = model.model.embed_tokens.cpu()\n",
        "    model.model.norm = model.model.norm.cpu()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    outs = torch.zeros_like(inps)\n",
        "    attention_mask = cache[\"attention_mask\"]\n",
        "\n",
        "    print(\"Ready.\")\n",
        "\n",
        "    quantizers = {}\n",
        "    for i in range(len(layers)):\n",
        "        layer = layers[i].to(dev)\n",
        "        full = find_layers(layer)\n",
        "\n",
        "        if args.true_sequential:\n",
        "            sequential = [\n",
        "                [\"self_attn.k_proj\", \"self_attn.v_proj\", \"self_attn.q_proj\"],\n",
        "                [\"self_attn.o_proj\"],\n",
        "                [\"mlp.up_proj\", \"mlp.gate_proj\"],\n",
        "                [\"mlp.down_proj\"],\n",
        "            ]\n",
        "        else:\n",
        "            sequential = [list(full.keys())]\n",
        "\n",
        "        for names in sequential:\n",
        "            subset = {n: full[n] for n in names}\n",
        "\n",
        "            gpts = {}\n",
        "            for name in subset:\n",
        "                if (\n",
        "                    not (args.minlayer <= i < args.maxlayer and args.prune_only in name)\n",
        "                ) == (not args.invert):\n",
        "                    continue\n",
        "                gpts[name] = SparseGPT(subset[name])\n",
        "                if args.wbits < 16:\n",
        "                    gpts[name].quantizer = Quantizer()\n",
        "                    gpts[name].quantizer.configure(\n",
        "                        args.wbits, perchannel=True, sym=False, mse=False\n",
        "                    )\n",
        "\n",
        "            def add_batch(name):\n",
        "                def tmp(_, inp, out):\n",
        "                    gpts[name].add_batch(inp[0].data, out.data)\n",
        "\n",
        "                return tmp\n",
        "\n",
        "            handles = []\n",
        "            for name in subset:\n",
        "                handles.append(subset[name].register_forward_hook(add_batch(name)))\n",
        "            for j in range(args.nsamples):\n",
        "                outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask)[0]\n",
        "            for h in handles:\n",
        "                h.remove()\n",
        "\n",
        "            for name in subset:\n",
        "                print(i, name)\n",
        "                print(\"Pruning ...\")\n",
        "                sparsity = args.sparsity\n",
        "                gpts[name].fasterprune(\n",
        "                    sparsity,\n",
        "                    prunen=args.prunen,\n",
        "                    prunem=args.prunem,\n",
        "                    percdamp=args.percdamp,\n",
        "                    blocksize=args.blocksize,\n",
        "                )\n",
        "                gpts[name].free()\n",
        "\n",
        "        for j in range(args.nsamples):\n",
        "            outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask)[0]\n",
        "\n",
        "        layers[i] = layer.cpu()\n",
        "        del layer\n",
        "        del gpts\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        inps, outs = outs, inps\n",
        "\n",
        "    model.config.use_cache = use_cache\n",
        "\n",
        "    return quantizers\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def llama_eval(model, testenc, dev,  dataset: str, log_wandb: bool = False):\n",
        "    print(\"Evaluating ...\")\n",
        "\n",
        "    testenc = testenc.input_ids\n",
        "    nsamples = testenc.numel() // model.seqlen\n",
        "\n",
        "    use_cache = model.config.use_cache\n",
        "    model.config.use_cache = False\n",
        "    layers = model.model.layers\n",
        "\n",
        "    model.model.embed_tokens = model.model.embed_tokens.to(dev)\n",
        "    layers[0] = layers[0].to(dev)\n",
        "\n",
        "    dtype = next(iter(model.parameters())).dtype\n",
        "    inps = torch.zeros(\n",
        "        (nsamples, model.seqlen, model.config.hidden_size), dtype=dtype, device=dev\n",
        "    )\n",
        "    cache = {\"i\": 0, \"attention_mask\": None}\n",
        "\n",
        "    class Catcher(nn.Module):\n",
        "        def __init__(self, module):\n",
        "            super().__init__()\n",
        "            self.module = module\n",
        "\n",
        "        def forward(self, inp, **kwargs):\n",
        "            inps[cache[\"i\"]] = inp\n",
        "            cache[\"i\"] += 1\n",
        "            cache[\"attention_mask\"] = kwargs[\"attention_mask\"]\n",
        "            raise ValueError\n",
        "\n",
        "    layers[0] = Catcher(layers[0])\n",
        "    for i in range(nsamples):\n",
        "        batch = testenc[:, (i * model.seqlen) : ((i + 1) * model.seqlen)].to(dev)\n",
        "        try:\n",
        "            model(batch)\n",
        "        except ValueError:\n",
        "            pass\n",
        "    layers[0] = layers[0].module\n",
        "\n",
        "    layers[0] = layers[0].cpu()\n",
        "    model.model.embed_tokens = model.model.embed_tokens.cpu()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    outs = torch.zeros_like(inps)\n",
        "    attention_mask = cache[\"attention_mask\"]\n",
        "\n",
        "    for i in range(len(layers)):\n",
        "        print(i)\n",
        "        layer = layers[i].to(dev)\n",
        "\n",
        "        if args.gmp:\n",
        "            subset = find_layers(layer)\n",
        "            for name in subset:\n",
        "                W = subset[name].weight.data\n",
        "                thresh = torch.sort(torch.abs(W.flatten()))[0][\n",
        "                    int(W.numel() * args.sparsity)\n",
        "                ]\n",
        "                W.data[torch.abs(W.data) <= thresh] = 0\n",
        "\n",
        "        for j in range(nsamples):\n",
        "            outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask)[0]\n",
        "        layers[i] = layer.cpu()\n",
        "        del layer\n",
        "        torch.cuda.empty_cache()\n",
        "        inps, outs = outs, inps\n",
        "\n",
        "    if model.model.norm is not None:\n",
        "        model.model.norm = model.model.norm.to(dev)\n",
        "    model.lm_head = model.lm_head.to(dev)\n",
        "\n",
        "    testenc = testenc.to(dev)\n",
        "    nlls = []\n",
        "    for i in range(nsamples):\n",
        "        hidden_states = inps[i].unsqueeze(0)\n",
        "        if model.model.norm is not None:\n",
        "            hidden_states = model.model.norm(hidden_states)\n",
        "        lm_logits = model.lm_head(hidden_states)\n",
        "        shift_logits = lm_logits[:, :-1, :].contiguous()\n",
        "        shift_labels = testenc[:, (i * model.seqlen) : ((i + 1) * model.seqlen)][:, 1:]\n",
        "        loss_fct = nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(\n",
        "            shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1)\n",
        "        )\n",
        "        neg_log_likelihood = loss.float() * model.seqlen\n",
        "        nlls.append(neg_log_likelihood)\n",
        "    ppl = torch.exp(torch.stack(nlls).sum() / (nsamples * model.seqlen))\n",
        "    print(f\"Perplexity: {ppl.item():3f}\")\n",
        "    if log_wandb:\n",
        "        wandb.log({f\"{dataset}/perplexity\": ppl.item()})\n",
        "\n",
        "    model.config.use_cache = use_cache\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "    from datautils import *\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"model\", type=str, help=\"LlaMA model to load\")\n",
        "    parser.add_argument(\n",
        "        \"dataset\",\n",
        "        type=str,\n",
        "        #choices=[\"wikitext2\", \"ptb\", \"c4\"],\n",
        "        help=\"Where to extract calibration data from.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--seed\", type=int, default=0, help=\"Seed for sampling the calibration data.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--nsamples\", type=int, default=128, help=\"Number of calibration data samples.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--percdamp\",\n",
        "        type=float,\n",
        "        default=0.01,\n",
        "        help=\"Percent of the average Hessian diagonal to use for dampening.\",\n",
        "    )\n",
        "    parser.add_argument(\"--sparsity\", type=float, default=0, help=\"Target sparsity\")\n",
        "    parser.add_argument(\"--prunen\", type=int, default=0, help=\"N for N:M pruning.\")\n",
        "    parser.add_argument(\"--prunem\", type=int, default=0, help=\"M for N:M pruning.\")\n",
        "    parser.add_argument(\n",
        "        \"--blocksize\",\n",
        "        type=int,\n",
        "        default=128,\n",
        "        help=\"Blocksize to use for adaptive mask selection.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gmp\", action=\"store_true\", help=\"Whether to run the GMP baseline.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--wbits\", type=int, default=16, help=\"Whether to quantize as well.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--minlayer\", type=int, default=-1, help=\"Prune all layers with id >= this.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--maxlayer\", type=int, default=1000, help=\"Prune all layers with id < this.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--prune_only\",\n",
        "        type=str,\n",
        "        default=\"\",\n",
        "        help=\"Prune only layers that contain this text.\",\n",
        "    )\n",
        "    parser.add_argument(\"--invert\", action=\"store_true\", help=\"Invert subset.\")\n",
        "    parser.add_argument(\"--save\", type=str, default=\"\", help=\"Path to saved model.\")\n",
        "    parser.add_argument(\n",
        "        \"--true-sequential\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to run in true sequential model.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--log_wandb\", action=\"store_true\", help=\"Whether to log to wandb.\"\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # init W&B logging\n",
        "    if args.log_wandb:\n",
        "        assert has_wandb, \"wandb not installed try `pip install wandb`\"\n",
        "        wandb.init(config=args)\n",
        "\n",
        "    model = get_llama(args.model)\n",
        "    model.eval()\n",
        "\n",
        "    dataloader, testloader = get_loaders(\n",
        "        args.dataset, nsamples=args.nsamples, seed=args.seed, model=args.model, seqlen=model.seqlen\n",
        "    )\n",
        "\n",
        "    if (args.sparsity or args.prunen) and not args.gmp:\n",
        "        tick = time.time()\n",
        "        llama_sequential(model, dataloader, DEV)\n",
        "        for n, p in model.named_parameters():\n",
        "            print(n, torch.mean((p == 0).float()))\n",
        "            if 'down_proj' in n:\n",
        "                break\n",
        "        print(time.time() - tick)\n",
        "\n",
        "    for dataset in [\"wikitext2\", \"ptb\", \"c4\"]:\n",
        "        dataloader, testloader = get_loaders(\n",
        "            dataset, seed=args.seed, model=args.model, seqlen=model.seqlen\n",
        "        )\n",
        "        print(\"Dataset:\", dataset)\n",
        "        llama_eval(model, testloader, DEV, dataset, args.log_wandb)\n",
        "\n",
        "    if args.save:\n",
        "        model.save_pretrained(args.save)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G29jkwCtqmEe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LoraLinear(nn.Linear):\n",
        "  def __init__(self, in_features, out_features, bias, linear, lora):\n",
        "    super().__init__(in_features, out_features, bias)\n",
        "    self.weight.data = linear.weight.data\n",
        "    if bias:\n",
        "      self.bias.data = linear.bias.data\n",
        "    self.lora = lora\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    print(f\"input_tensor.shape = {input_tensor.shape}\")\n",
        "    out = super().forward(input_tensor)\n",
        "    print(f\"out.shape = {out.shape} , self.lora(input_tensor).shape = {self.lora(input_tensor).shape}\")\n",
        "    out = (out + self.lora(input_tensor))/2.0\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Az9-G-otqyuQ"
      },
      "outputs": [],
      "source": [
        "def create_factorized_compression_for_linear(source_linear, rank=None, rank_factor=0.3,  dtype=torch.float32):\n",
        "    with torch.no_grad():\n",
        "      if rank is None:\n",
        "        rank = max(1, int(min(source_linear.weight.shape)*rank_factor))\n",
        "      if hasattr(source_linear, 'bias'):\n",
        "        bias = source_linear.bias\n",
        "      else:\n",
        "        bias = None\n",
        "      source_linear = source_linear.weight.data\n",
        "      device=source_linear.device\n",
        "      assert rank < min(source_linear.shape)\n",
        "      source_linear = source_linear.float()\n",
        "      U, S, Vh = torch.linalg.svd(source_linear)\n",
        "      U = U[:, :rank]\n",
        "      S = S[:rank]\n",
        "      U = U @ torch.diag(S)\n",
        "      Vh = Vh[:rank, :]\n",
        "      U_flatten = U.flatten()\n",
        "      Vh_flatten = Vh.flatten()\n",
        "      max_quant_size = 2^23\n",
        "      #print (\"ranked\")\n",
        "      if len(U_flatten) + len(Vh_flatten) >= max_quant_size:\n",
        "        dist2 = U_flatten[:min(len(U_flatten), max_quant_size)]\n",
        "        dist3 = Vh_flatten[:min(len(Vh_flatten), max_quant_size)]\n",
        "        hi_val = max(torch.quantile(dist3, 1), torch.quantile(dist2, 1))\n",
        "      else:\n",
        "        dist = torch.cat([U_flatten, Vh_flatten])\n",
        "        hi_val = torch.quantile(dist, 1)\n",
        "      low_val = -hi_val\n",
        "      #print (\"quantile\")\n",
        "      U = U.clamp(low_val, hi_val)\n",
        "      Vh = Vh.clamp(low_val, hi_val)\n",
        "      #print (\"clammped\")\n",
        "      print(f\"U.shape = {U.shape}\")\n",
        "      print(f\"Vh.shape = {Vh.shape}\")\n",
        "\n",
        "      lora_down = nn.Linear(Vh.shape[1], Vh.shape[0], dtype=dtype, bias=False, device=source_linear.device)\n",
        "      lora_up = nn.Linear(U.shape[1], U.shape[0], dtype=dtype, bias=bias is not None, device=source_linear.device)\n",
        "      #print (\"Set up linear\")\n",
        "      lora_up.weight.data = U.to(device=device, dtype=dtype)\n",
        "      lora_down.weight.data = Vh.to(device=device, dtype=dtype)\n",
        "      if bias is not None:\n",
        "        lora_up.bias = nn.Parameter(bias.clone())\n",
        "      return nn.Sequential(lora_down, lora_up)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v01GGPjNqw4B"
      },
      "outputs": [],
      "source": [
        "import cupy\n",
        "\n",
        "def lord_decompose(layer, proxy_data, rank):\n",
        "    \"\"\"\n",
        "    Be aware when performing LoRD/AFM on Square Matrices:\n",
        "\n",
        "        In square matrices, input and output dimensions are coupled so compression is more challenging.\n",
        "        The optimal low rank approximation may differ significantly from the original matrix due to the coupling.\n",
        "        Square matrices have less intrinsic redundancy between inputs and outputs to exploit.\n",
        "        Decomposing square matrices risks distorting dimensions that interact in complex ways.\n",
        "        The approximation error of AFM tends to be lowest for tall matrices and highest for square ones.\n",
        "        For square matrices, it can help to decompose blocks of interactions rather than the whole matrix.\n",
        "\n",
        "    Paper reference:\n",
        "        Low Rank Decomposition Of Monolingual Code LLMs For One-Shot Compression\n",
        "        ( http://arxiv.org/abs/2309.14021 )\n",
        "\n",
        "    Credit: AI chatbot\n",
        "    \"\"\"\n",
        "\n",
        "    y = layer(proxy_data) # Forward proxy data\n",
        "\n",
        "    cov_y = torch.cov(y.T) # Compute output covariance\n",
        "    cov_y = cov_y.float()\n",
        "\n",
        "    eigenvalues, eigenvectors = torch.linalg.eig(cov_y)\n",
        "\n",
        "    # Allocate CuPy array\n",
        "    eigenvalues_cupy = cupy.empty(eigenvalues.shape, dtype=cupy.complex64)\n",
        "\n",
        "    # Copy with CUDA stream\n",
        "    eigenvalues_cupy = cupy.from_dlpack(torch.utils.dlpack.to_dlpack(eigenvalues))\n",
        "\n",
        "    # Take top rank eigenvectors in descending order\n",
        "    # [-rank:] selects the last rank indices, which correspond to the largest rank values.\n",
        "    # [::-1] then reverses the array to give the indices that would sort eigenvalues_cupy in descending order.\n",
        "    top_idx = cupy.argsort(cupy.abs(eigenvalues_cupy))[-rank:][::-1]\n",
        "\n",
        "    # PyTorch (eigenvectors) and CuPy (top_idx) arrays can't be indexed against each other like this due to incompatible types.\n",
        "    top_idx_pt = torch.from_numpy(top_idx.get())\n",
        "    U = eigenvectors[:, top_idx_pt]\n",
        "\n",
        "    # Convert layer weight to complex before decomposition\n",
        "    layer.weight = nn.Parameter(layer.weight.to(torch.complex64))\n",
        "\n",
        "    # Decompose\n",
        "    w1 = U.T @ layer.weight\n",
        "    w2 = U\n",
        "    print(f\"w1.shape = {w1.shape}\")\n",
        "    print(f\"w2.shape = {w2.shape}\")\n",
        "\n",
        "    # Create LoRD layers\n",
        "    lord_up = nn.Linear(w2.shape[1], w2.shape[0])\n",
        "    lord_down = nn.Linear(w1.shape[1], w1.shape[0])\n",
        "\n",
        "    lord_up.weight.data = torch.real(torch.abs(w2))\n",
        "    lord_down.weight.data = torch.real(torch.abs(w1))\n",
        "\n",
        "    return nn.Sequential(lord_down, lord_up)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "1ed086af6b034b4bb040753b3683da11",
            "d74209c5ad674dabb198cf4ac46a519f",
            "2c363d51b32b438e91648fa7219a03c6",
            "072f4e0b728b46bcb3319c49d2156faf",
            "6e77d83ac3d14726964b21d323fb152a",
            "f342cb94bdbb4fc7967cbb05f2bbc39e",
            "3eb645896ddf470d9a8f63d0227a323e",
            "fa11c653cd2d45c985861f018f2c191b",
            "77ddfcf70fef4325ad7ada2229e1a449",
            "aaa7c92ad8874fed9a347babb1942218",
            "41cd31ec41394cd2ad64045c2ee9564e",
            "8c37e60a030c4f549b9716ed4f011f73",
            "ceea64e8e6ae427ba3b06f398de75ba0",
            "7b2797ed1ef549d5b1e8b0f9c1699c51",
            "da16ce8f18ef41ddb9125e3f33b887d5",
            "d7f6c79863da41bb911cf6d33132f850",
            "ad574f566a444e97963cc9220757d3fa",
            "7552b614217f485592ae474b4021b786",
            "a9896fbce5ba4fc49c2dc96ff27f660e",
            "87a0a520d7f044eba78688c400ddc6a8",
            "e755a7bdffd24a16829e8d206518f219",
            "0d3e7144e5ec49eaab3778c8f9cbe3df",
            "578f4af6302c41c7883be9f56bfc32ff",
            "98e0c747b3034c5aac362f4e36b17c17",
            "1e3cc2bc727446619fdb7b8a77409977",
            "af4bf3bc80eb42e2a01ee969a5f7e437",
            "0c4efc92565949269b1b4687f9895eb1",
            "e339c990418247e781db8d153c7cd3c4",
            "2be7f764512949b69876738366982048",
            "a691240e41874c43ad5e519b4af0225b",
            "0f147d76905546629fd8727d6c7d2cfb",
            "db38e73a78114e24889b7fe0599c2e0a",
            "4ad7fab136e240d494bae95fe2a378db",
            "9ab76d2545c3475fb09fb76993534820",
            "87e67bdf49b24fc980a33846d0b58e8d",
            "8f806324f0904911bb182fdda326f4e4",
            "f338521badfe495c8a27eee44af95ab1",
            "4c3e0ffdfce64c769e67b8b0c7b4d5a2",
            "d73c69db05894943888fb24f73a701d6",
            "6149471fa51e43c2820116412cfcd09b",
            "f4247b83dd6b45e9b4cdfb31c59ca9c1",
            "7b8005f270d44f05ac29636351e49d02",
            "876259b9a911464caae6b1afc5656c3b",
            "a1b6b494fcb34dd0befa4debc650fd5a",
            "cc619a053fa54cfd8d8654d2a43349b9",
            "4081ef3d79e246d6868e23fda48b9b6d",
            "c91accb5843d4be4af54743530d747da",
            "6f834119950b4fe6acb6c6ce21e9423c",
            "0fc8b45f8c25486eb75a8165117912b9",
            "49cdd3570a5e45d9925cb0627e673644",
            "35459dee71a84092995acd0de0b1238c",
            "1301af302e704c4e95af86cc02b34321",
            "ff92d002eafd437badbcae2eb95f0b0e",
            "acf85760568a455188b9bde239bfe0c8",
            "ce5c36eafc1b40fd98f7398e44fc0181"
          ]
        },
        "id": "KRL54Os9tDN_",
        "outputId": "e250add3-9191-4865-98ec-24646919f3ad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ed086af6b034b4bb040753b3683da11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/911M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c37e60a030c4f549b9716ed4f011f73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "578f4af6302c41c7883be9f56bfc32ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ab76d2545c3475fb09fb76993534820"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc619a053fa54cfd8d8654d2a43349b9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import Optional, Tuple, Union\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers.models.gpt_neox.configuration_gpt_neox import *\n",
        "\n",
        "\n",
        "model_name = \"EleutherAI/pythia-410m\" #\"EleutherAI/pythia-70m\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, low_cpu_mem_usage=True ).cuda()\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#model.embed_out  = create_factorized_compression_for_linear(model.embed_out, rank_factor=0.9).cuda().to(torch.bfloat16)\n",
        "#model.gpt_neox.embed_in = create_factorized_compression_for_linear(model.gpt_neox.embed_in, rank_factor=0.2).cuda().to(torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qnwVwUyeq-SV"
      },
      "outputs": [],
      "source": [
        "# Generate proxy dataset\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "proxy_texts = [\n",
        "  \"The cat sat on the mat.\",\n",
        "  \"The quick brown fox jumps over the lazy dog.\",\n",
        "  \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\",\n",
        "  \"In my younger and more vulnerable years my father gave me some advice that I've been turning over in my mind ever since.\",\n",
        "  \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.\",\n",
        "  \"In a hole in the ground there lived a hobbit.\",\n",
        "  \"Happy families are all alike; every unhappy family is unhappy in its own way.\",\n",
        "  \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of light, it was the season of darkness, it was the spring of hope, it was the winter of despair.\",\n",
        "  \"I was born in the year 1632, in the city of York, of a good family, though not of that country, my father being a foreigner of Bremen, who settled first at Hull.\",\n",
        "  \"Many years later, as he faced the firing squad, Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice.\",\n",
        "  \"The sun shone, having no alternative, on the nothing new.\",\n",
        "  \"I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.\",\n",
        "  \"When he was nearly thirteen, my brother Jem got his arm badly broken at the elbow.\",\n",
        "  \"There was a boy called Eustace Clarence Scrubb, and he almost deserved it.\",\n",
        "  \"The primroses were over.\",\n",
        "  \"Many years later, as he faced the firing squad, Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice.\",\n",
        "  \"Riverrun, past Eve and Adam's, from swerve of shore to bend of bay, brings us by a commodius vicus of recirculation back to Howth Castle and Environs.\",\n",
        "  \"124 was spiteful.\",\n",
        "  \"The cold passed reluctantly from the earth, and the retiring fogs revealed an army stretched out on the hills, resting.\",\n",
        "  \"We shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender.\",\n",
        "  \"I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.\",\n",
        "  \"Ask not what your country can do for you – ask what you can do for your country.\",\n",
        "  \"The only thing we have to fear is fear itself.\",\n",
        "  \"I do not agree with what you have to say, but I'll defend to the death your right to say it.\",\n",
        "  \"The future belongs to those who believe in the beauty of their dreams.\",\n",
        "  \"It does not matter how slowly you go as long as you do not stop.\"\n",
        "  \"Be who you are and say what you feel, because those who mind don't matter and those who matter don't mind.\",\n",
        "  \"We hold these truths to be self-evident, that all men are created equal, that they are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.\",\n",
        "  # Add more samples from diverse books, speeches, genres etc.\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QQZuy6HqzQs",
        "outputId": "f50ec0f9-8069-4a1b-fe63-e88aa6ede577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(model.gpt_neox.layers) = 24\n",
            "now processing layer [0]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1143: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:276.)\n",
            "  return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [2]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [4]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [6]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [8]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [10]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [12]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [14]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [16]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [18]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [20]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "now processing layer [22]\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([1024, 512])\n",
            "w1.shape = torch.Size([512, 1024])\n",
            "w2.shape = torch.Size([4096, 512])\n",
            "w1.shape = torch.Size([512, 4096])\n",
            "w2.shape = torch.Size([1024, 512])\n"
          ]
        }
      ],
      "source": [
        "USE_LORD = 1\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "if USE_LORD:\n",
        "  rank_factor=0.5\n",
        "\n",
        "  print(f\"len(model.gpt_neox.layers) = {len(model.gpt_neox.layers)}\")\n",
        "\n",
        "  #for layer in model.gpt_neox.layers:\n",
        "  for i in range(0, len(model.gpt_neox.layers), 2):\n",
        "    layer = model.gpt_neox.layers[i]\n",
        "\n",
        "    print(f\"now processing layer [{i}]\")\n",
        "\n",
        "    input_dim = layer.attention.dense.in_features\n",
        "    rank = int(input_dim * rank_factor)\n",
        "\n",
        "\n",
        "    max_length_dense_h_to_4h = layer.mlp.dense_h_to_4h.in_features # Max sequence length\n",
        "    proxy_data_h = tokenizer(proxy_texts, padding=\"max_length\", truncation=True, max_length=max_length_dense_h_to_4h, return_tensors=\"pt\").to(\"cuda\")\n",
        "    proxy_data_h_bf16 = proxy_data_h['input_ids'].to(torch.bfloat16)\n",
        "\n",
        "    max_length_dense_4h_to_h = layer.mlp.dense_4h_to_h.in_features # Max sequence length\n",
        "    proxy_data_4h = tokenizer(proxy_texts, padding=\"max_length\", truncation=True, max_length=max_length_dense_4h_to_h, return_tensors=\"pt\").to(\"cuda\")\n",
        "    proxy_data_4h_bf16 = proxy_data_4h['input_ids'].to(torch.bfloat16)\n",
        "\n",
        "\n",
        "    layer.attention.dense = LoraLinear(layer.attention.dense.in_features, layer.attention.dense.out_features, layer.attention.dense.bias is not None,  layer.attention.dense, \\\n",
        "                                      lord_decompose(layer.attention.dense, proxy_data_h_bf16, rank)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    #layer.attention.query_key_value = LoraLinear(layer.attention.query_key_value.in_features, layer.attention.query_key_value.out_features, layer.attention.query_key_value.bias is not None, layer.attention.query_key_value, \\\n",
        "    #                                   lord_decompose(layer.attention.query_key_value, proxy_data, rank)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    layer.mlp.dense_h_to_4h = LoraLinear(layer.mlp.dense_h_to_4h.in_features, layer.mlp.dense_h_to_4h.out_features, layer.mlp.dense_h_to_4h.bias is not None, layer.mlp.dense_h_to_4h, \\\n",
        "                                      lord_decompose(layer.mlp.dense_h_to_4h, proxy_data_h_bf16, rank)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    layer.mlp.dense_4h_to_h = LoraLinear(layer.mlp.dense_4h_to_h.in_features, layer.mlp.dense_4h_to_h.out_features, layer.mlp.dense_4h_to_h.bias is not None, layer.mlp.dense_4h_to_h, \\\n",
        "                                      lord_decompose(layer.mlp.dense_4h_to_h, proxy_data_4h_bf16, rank)).cuda().to(torch.bfloat16)\n",
        "\n",
        "else:\n",
        "\n",
        "  #for layer in model.gpt_neox.layers:\n",
        "  for i in range(0, len(model.gpt_neox.layers), 2):\n",
        "    layer = model.gpt_neox.layers[i]\n",
        "\n",
        "    print(f\"now processing layer [{i}]\")\n",
        "\n",
        "    layer.attention.dense = LoraLinear(layer.attention.dense.in_features, layer.attention.dense.out_features, layer.attention.dense.bias is not None,  layer.attention.dense, \\\n",
        "                                      create_factorized_compression_for_linear(layer.attention.dense, rank_factor=0.2)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    #layer.attention.query_key_value = LoraLinear(layer.attention.query_key_value.in_features, layer.attention.query_key_value.out_features, layer.attention.query_key_value.bias is not None, layer.attention.query_key_value, \\\n",
        "    #                                   create_factorized_compression_for_linear(layer.attention.query_key_value, rank_factor=0.5)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    layer.mlp.dense_h_to_4h = LoraLinear(layer.mlp.dense_h_to_4h.in_features, layer.mlp.dense_h_to_4h.out_features, layer.mlp.dense_h_to_4h.bias is not None, layer.mlp.dense_h_to_4h, \\\n",
        "                                      create_factorized_compression_for_linear(layer.mlp.dense_h_to_4h, rank_factor=0.5)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    layer.mlp.dense_4h_to_h = LoraLinear(layer.mlp.dense_4h_to_h.in_features, layer.mlp.dense_4h_to_h.out_features, layer.mlp.dense_4h_to_h.bias is not None, layer.mlp.dense_4h_to_h, \\\n",
        "                                      create_factorized_compression_for_linear(layer.mlp.dense_4h_to_h, rank_factor=0.5)).cuda().to(torch.bfloat16)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(txt, return_tensors=\"pt\").to(\"cuda\")\n",
        "print(f\"input_ids.input_ids.shape = {input_ids.input_ids.shape}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  print(tokenizer.batch_decode(model.generate(**input_ids,  no_repeat_ngram_size=2, repetition_penalty=1.1, min_length=input_ids.input_ids.shape[1]+256, max_new_tokens=512))[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7BxVMUbLp3P",
        "outputId": "a974c14d-2df6-4d92-f81d-0b124701fdb1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "input_tensor.shape = torch.Size([1, 1, 1024])\n",
            "out.shape = torch.Size([1, 1, 4096]) , self.lora(input_tensor).shape = torch.Size([1, 1, 4096])\n",
            "input_tensor.shape = torch.Size([1, 1, 4096])\n",
            "out.shape = torch.Size([1, 1, 1024]) , self.lora(input_tensor).shape = torch.Size([1, 1, 1024])\n",
            "Abraham Lincoln (/ˈlɪŋkən/ LINK-ən; February 12, 1809 – April 15, 1865) was an American lawyer, politician, and statesman who served as the 16th president of the United States from 1861 until his assassination in 1865. Lincoln led the Union through the American Civil War to defend the nation as a constitutional union and succeeded in abolishing slavery, bolstering the federal government, and modernizing the U.S. economy.\n",
            "\n",
            "Lincoln was born into poverty in a log cabin in Kentucky and was raised on the frontier, primarily in Indiana. He was self-educated and became a lawyer, Whig Party leader, Illinois state legislator, and U.S. Congressman from Illinois. In 1849, he returned to his successful law practice in Springfield, Illinois. In 1854, he was angered by the Kansas–Nebraska Act, which opened the territories to slavery, and he re-entered politics. He soon became a leader of the new Republican Party. He reached a national audience in the 1858 Senate campaign debates against Stephen A. Douglas. Lincoln ran for president in 1860, sweeping the North to gain victory. Pro-slavery elements in the South viewed his election as a threat to slavery, and Southern states began seceding from the nation. During this time, the newly formed Confederate States of America began seizing federal military bases in the south. Just over one month after Lincoln assumed the presidency, the Confederate States attacked Fort Sumter, a U.S. fort in South Carolina. Following the bombardment, Lincoln mobilized forces to suppress the rebellion and restore the union.\n",
            "\n",
            "\n",
            "Marriage and children\n",
            "\n",
            "Lincoln had pledged in 1846 to serve only one term in the House. Realizing Clay was unlikely to win the presidency, he supported General Zachary Taylor for the Whig nomination in the 1848 presidential election.[85] Taylor won and Lincoln hoped in vain to be appointed Commissioner of the General Land Office.[86] The administration offered to appoint him secretary or governor of the Oregon Territory as consolation.[87] This distant territory was a Democratic stronghold, and acceptance of the post would have disrupted his legal and political career in Illinois, so he declined and resumed his law practice.[88]\n",
            "\n",
            "Lincoln's second child was namedolu assigned natureolu Natureololu1234 intuition givenolu assign charge FIGolu assignment Natureoluyessolu given nature naturecharge intuition assignedoluolu questionolu provided nature branched nature charged viewolu academutative intuition Nature nature figureoluPSoluioroluassignolu collected NatureernoluNatureolu evalolupatoluKP assignedought intuition practitioner assigned Natureulpoluukary intuitionASTolu examiner assigned charge assignedyolu Instruments assignedol natureololpsilonoluompolu’olu performedolu gottenolu0123 intuitionFIG Naturenatureolu../../ assignedchargeeltaolu aside assigned branchedoluolved nature charge Natureyoly nature Natureolveolu Societyoluhisolu natureyern naturehenceolu amazed Nature NaturechargeAAoluVS Natureess naturesor assigned charged nature oluISS assigned met natureoughtounter assignedativityoluhey intuition1234ounding Natureheast Nature charge1234Syscall intuition availableolu examolu diagnose assigned intuition intuition example Natureought FIG natureulp nature intuition FIG charge givenolcharge FIGcharge1021 intuitionolu cheating intuition distributionoluhsoluASolu44olu despiteoluuholu perfolu Physicsolu FIGol Nature chargedoluhaoluexample assigned view naturenature natureii assigned figure naturenessolucharge attendedolu perspective assignedORN intuition bestolu charged intuition assignmentolueah assigneductoluindi intuition brokenolu assignments Nature figureol charge intuition providedoluAST nature hack assignedpsilon nature viewol branched intuitionutative FIG branchedutessolulpol figureyyordinate intuitionounderolu ECM intuition assign nature ticket assigned noteoluAI assignedackeroluas naturepsilonol charged chargeolucharged intuition eoluuriesoluoughtutative Natureeon intuition Exampleolu distribute Natureioned intuition answeringolu blowolu pointedolu� assignedulpyulpessynatureolought comparisonolugia assignednaturey Nature Russell assignedvsoluInstroluewolu believed assigned olernolialolu standpointoluperf assigned ideaolu taughtoluois intuition viewytheory natureessulpernyoughtoley assignedmann assigned falseolu Oolu questionsolujcmm intuition society Naturehence natureern Nature branchedcharge life assigned amateur intuitionOoluiscus intuition answerolu Allaholueval assignedsor Natureorn intuition fortunate assigned->olu  oluolatedolu discussedolu overhead intuition questionoless Natureorio intuitionounter Nature instantoluiddell intuition likeolu nonsense intuition examinationolu observationolu physic assigned assignment assigned othersoluernessessoughtolu0olu  nature fireolu Performanceolu intuitionodb intuition academ intuitionelta natureolve nature metolu detr intuition discussionolu reviewedolu practitioner Naturepsilonyheitolukas Nature|- assignedii NatureRuss1234 FIG Natureroticolu(-oluischer assigned advolu80olu covered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_orig = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, low_cpu_mem_usage=True ).cuda()\n",
        "print('compression', sum(x.shape[0]*x.shape[1] if len(x.shape) == 2 else x.shape[0] for x in model.parameters())/ sum(x.shape[0]*x.shape[1] if len(x.shape) == 2 else x.shape[0] for x in model_orig.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDVEgPnFRPL9",
        "outputId": "b08cbe27-b428-4217-fc58-bd3d2109d875"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compression 1.1864872648635538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n",
        "\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "6ggkiW6pLz--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe741561-abc9-4e72-f23a-2d58ce8aeb2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 188909568 || all params: 480923648 || trainable%: 39.28057370137889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TFUaGmHxkA5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c761a31d-e961-42da-8d55-bb913615c2dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 1024)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (1): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (2): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (3): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (4): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (5): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (6): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (7): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (8): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (9): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (10): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (11): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (12): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (13): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (14): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (15): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (16): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (17): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (18): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (19): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (20): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (21): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (22): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "              (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (23): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_orig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9tpn-OU-Dur",
        "outputId": "f82b07f8-3e4f-4749-9c3f-05545a732c5a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 1024)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ed086af6b034b4bb040753b3683da11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d74209c5ad674dabb198cf4ac46a519f",
              "IPY_MODEL_2c363d51b32b438e91648fa7219a03c6",
              "IPY_MODEL_072f4e0b728b46bcb3319c49d2156faf"
            ],
            "layout": "IPY_MODEL_6e77d83ac3d14726964b21d323fb152a"
          }
        },
        "d74209c5ad674dabb198cf4ac46a519f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f342cb94bdbb4fc7967cbb05f2bbc39e",
            "placeholder": "​",
            "style": "IPY_MODEL_3eb645896ddf470d9a8f63d0227a323e",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "2c363d51b32b438e91648fa7219a03c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa11c653cd2d45c985861f018f2c191b",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77ddfcf70fef4325ad7ada2229e1a449",
            "value": 570
          }
        },
        "072f4e0b728b46bcb3319c49d2156faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaa7c92ad8874fed9a347babb1942218",
            "placeholder": "​",
            "style": "IPY_MODEL_41cd31ec41394cd2ad64045c2ee9564e",
            "value": " 570/570 [00:00&lt;00:00, 24.8kB/s]"
          }
        },
        "6e77d83ac3d14726964b21d323fb152a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f342cb94bdbb4fc7967cbb05f2bbc39e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eb645896ddf470d9a8f63d0227a323e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa11c653cd2d45c985861f018f2c191b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ddfcf70fef4325ad7ada2229e1a449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aaa7c92ad8874fed9a347babb1942218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41cd31ec41394cd2ad64045c2ee9564e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c37e60a030c4f549b9716ed4f011f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceea64e8e6ae427ba3b06f398de75ba0",
              "IPY_MODEL_7b2797ed1ef549d5b1e8b0f9c1699c51",
              "IPY_MODEL_da16ce8f18ef41ddb9125e3f33b887d5"
            ],
            "layout": "IPY_MODEL_d7f6c79863da41bb911cf6d33132f850"
          }
        },
        "ceea64e8e6ae427ba3b06f398de75ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad574f566a444e97963cc9220757d3fa",
            "placeholder": "​",
            "style": "IPY_MODEL_7552b614217f485592ae474b4021b786",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "7b2797ed1ef549d5b1e8b0f9c1699c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9896fbce5ba4fc49c2dc96ff27f660e",
            "max": 911373632,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87a0a520d7f044eba78688c400ddc6a8",
            "value": 911373632
          }
        },
        "da16ce8f18ef41ddb9125e3f33b887d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e755a7bdffd24a16829e8d206518f219",
            "placeholder": "​",
            "style": "IPY_MODEL_0d3e7144e5ec49eaab3778c8f9cbe3df",
            "value": " 911M/911M [00:04&lt;00:00, 236MB/s]"
          }
        },
        "d7f6c79863da41bb911cf6d33132f850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad574f566a444e97963cc9220757d3fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7552b614217f485592ae474b4021b786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9896fbce5ba4fc49c2dc96ff27f660e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a0a520d7f044eba78688c400ddc6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e755a7bdffd24a16829e8d206518f219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d3e7144e5ec49eaab3778c8f9cbe3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "578f4af6302c41c7883be9f56bfc32ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98e0c747b3034c5aac362f4e36b17c17",
              "IPY_MODEL_1e3cc2bc727446619fdb7b8a77409977",
              "IPY_MODEL_af4bf3bc80eb42e2a01ee969a5f7e437"
            ],
            "layout": "IPY_MODEL_0c4efc92565949269b1b4687f9895eb1"
          }
        },
        "98e0c747b3034c5aac362f4e36b17c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e339c990418247e781db8d153c7cd3c4",
            "placeholder": "​",
            "style": "IPY_MODEL_2be7f764512949b69876738366982048",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "1e3cc2bc727446619fdb7b8a77409977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a691240e41874c43ad5e519b4af0225b",
            "max": 396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f147d76905546629fd8727d6c7d2cfb",
            "value": 396
          }
        },
        "af4bf3bc80eb42e2a01ee969a5f7e437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db38e73a78114e24889b7fe0599c2e0a",
            "placeholder": "​",
            "style": "IPY_MODEL_4ad7fab136e240d494bae95fe2a378db",
            "value": " 396/396 [00:00&lt;00:00, 13.1kB/s]"
          }
        },
        "0c4efc92565949269b1b4687f9895eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e339c990418247e781db8d153c7cd3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2be7f764512949b69876738366982048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a691240e41874c43ad5e519b4af0225b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f147d76905546629fd8727d6c7d2cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db38e73a78114e24889b7fe0599c2e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ad7fab136e240d494bae95fe2a378db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ab76d2545c3475fb09fb76993534820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87e67bdf49b24fc980a33846d0b58e8d",
              "IPY_MODEL_8f806324f0904911bb182fdda326f4e4",
              "IPY_MODEL_f338521badfe495c8a27eee44af95ab1"
            ],
            "layout": "IPY_MODEL_4c3e0ffdfce64c769e67b8b0c7b4d5a2"
          }
        },
        "87e67bdf49b24fc980a33846d0b58e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d73c69db05894943888fb24f73a701d6",
            "placeholder": "​",
            "style": "IPY_MODEL_6149471fa51e43c2820116412cfcd09b",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "8f806324f0904911bb182fdda326f4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4247b83dd6b45e9b4cdfb31c59ca9c1",
            "max": 2113710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b8005f270d44f05ac29636351e49d02",
            "value": 2113710
          }
        },
        "f338521badfe495c8a27eee44af95ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_876259b9a911464caae6b1afc5656c3b",
            "placeholder": "​",
            "style": "IPY_MODEL_a1b6b494fcb34dd0befa4debc650fd5a",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 11.0MB/s]"
          }
        },
        "4c3e0ffdfce64c769e67b8b0c7b4d5a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d73c69db05894943888fb24f73a701d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6149471fa51e43c2820116412cfcd09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4247b83dd6b45e9b4cdfb31c59ca9c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b8005f270d44f05ac29636351e49d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "876259b9a911464caae6b1afc5656c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1b6b494fcb34dd0befa4debc650fd5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc619a053fa54cfd8d8654d2a43349b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4081ef3d79e246d6868e23fda48b9b6d",
              "IPY_MODEL_c91accb5843d4be4af54743530d747da",
              "IPY_MODEL_6f834119950b4fe6acb6c6ce21e9423c"
            ],
            "layout": "IPY_MODEL_0fc8b45f8c25486eb75a8165117912b9"
          }
        },
        "4081ef3d79e246d6868e23fda48b9b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49cdd3570a5e45d9925cb0627e673644",
            "placeholder": "​",
            "style": "IPY_MODEL_35459dee71a84092995acd0de0b1238c",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "c91accb5843d4be4af54743530d747da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1301af302e704c4e95af86cc02b34321",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff92d002eafd437badbcae2eb95f0b0e",
            "value": 99
          }
        },
        "6f834119950b4fe6acb6c6ce21e9423c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acf85760568a455188b9bde239bfe0c8",
            "placeholder": "​",
            "style": "IPY_MODEL_ce5c36eafc1b40fd98f7398e44fc0181",
            "value": " 99.0/99.0 [00:00&lt;00:00, 986B/s]"
          }
        },
        "0fc8b45f8c25486eb75a8165117912b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49cdd3570a5e45d9925cb0627e673644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35459dee71a84092995acd0de0b1238c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1301af302e704c4e95af86cc02b34321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff92d002eafd437badbcae2eb95f0b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acf85760568a455188b9bde239bfe0c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5c36eafc1b40fd98f7398e44fc0181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
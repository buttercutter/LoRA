{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhuWJXn7X7-Z",
        "outputId": "af0673d0-7c57-4bd6-e0b9-13fc257fe360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sparsegpt'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 37 (delta 18), reused 9 (delta 9), pack-reused 11\u001b[K\n",
            "Receiving objects: 100% (37/37), 21.78 KiB | 10.89 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Copyright 2023 Ontocord.AI, Apache 2 License\n",
        "# Create Use sparsification on a specific data distribution, and SVD to create Loras from sparsified network.\n",
        "\n",
        "!git clone https://github.com/IST-DASLab/sparsegpt\n",
        "\n",
        "\n",
        "txt = \"\"\"Abraham Lincoln (/ˈlɪŋkən/ LINK-ən; February 12, 1809 – April 15, 1865) was an American lawyer, politician, and statesman who served as the 16th president of the United States from 1861 until his assassination in 1865. Lincoln led the Union through the American Civil War to defend the nation as a constitutional union and succeeded in abolishing slavery, bolstering the federal government, and modernizing the U.S. economy.\n",
        "\n",
        "Lincoln was born into poverty in a log cabin in Kentucky and was raised on the frontier, primarily in Indiana. He was self-educated and became a lawyer, Whig Party leader, Illinois state legislator, and U.S. Congressman from Illinois. In 1849, he returned to his successful law practice in Springfield, Illinois. In 1854, he was angered by the Kansas–Nebraska Act, which opened the territories to slavery, and he re-entered politics. He soon became a leader of the new Republican Party. He reached a national audience in the 1858 Senate campaign debates against Stephen A. Douglas. Lincoln ran for president in 1860, sweeping the North to gain victory. Pro-slavery elements in the South viewed his election as a threat to slavery, and Southern states began seceding from the nation. During this time, the newly formed Confederate States of America began seizing federal military bases in the south. Just over one month after Lincoln assumed the presidency, the Confederate States attacked Fort Sumter, a U.S. fort in South Carolina. Following the bombardment, Lincoln mobilized forces to suppress the rebellion and restore the union.\n",
        "\n",
        "\n",
        "Marriage and children\n",
        "\n",
        "Lincoln had pledged in 1846 to serve only one term in the House. Realizing Clay was unlikely to win the presidency, he supported General Zachary Taylor for the Whig nomination in the 1848 presidential election.[85] Taylor won and Lincoln hoped in vain to be appointed Commissioner of the General Land Office.[86] The administration offered to appoint him secretary or governor of the Oregon Territory as consolation.[87] This distant territory was a Democratic stronghold, and acceptance of the post would have disrupted his legal and political career in Illinois, so he declined and resumed his law practice.[88]\n",
        "\n",
        "Lincoln's second child was named\"\"\"\n",
        "\n",
        "try:\n",
        "  import accelerate, bitsandbytes\n",
        "  from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "except:\n",
        "  !pip install -q transformers accelerate bitsandbytes\n",
        "  !pip install -q datasets\n",
        "  !pip install -q sentencepiece\n",
        "  !pip install -q zstandard\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibVz6SUDbNRT",
        "outputId": "7e7c0105-d905-4c2d-8048-9bfa1c526cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sparsegpt/datautils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile sparsegpt/datautils.py\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, LlamaTokenizer\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.random.manual_seed(seed)\n",
        "\n",
        "def get_tokenizer(model):\n",
        "    if \"llama\" in model.lower():\n",
        "        tokenizer = LlamaTokenizer.from_pretrained(model, use_fast=False)\n",
        "        # fix for transformer 4.28.0.dev0 compatibility\n",
        "        if tokenizer.bos_token_id != 1 or tokenizer.eos_token_id != 2:\n",
        "            try:\n",
        "                tokenizer.bos_token_id = 1\n",
        "                tokenizer.eos_token_id = 2\n",
        "            except AttributeError:\n",
        "                pass\n",
        "    else:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model, use_fast=False)\n",
        "    return tokenizer\n",
        "\n",
        "def get_wikitext2(nsamples, seed, seqlen, model, tokenizer):\n",
        "\n",
        "    traindata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train')\n",
        "    testdata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
        "\n",
        "    trainenc = tokenizer(\" \".join(traindata['text']), return_tensors='pt')\n",
        "    testenc = tokenizer(\"\\n\\n\".join(testdata['text']), return_tensors='pt')\n",
        "\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in range(nsamples):\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "    return trainloader, testenc\n",
        "\n",
        "def get_ptb(nsamples, seed, seqlen, model, tokenizer):\n",
        "    traindata = load_dataset('ptb_text_only', 'penn_treebank', split='train')\n",
        "    testdata = load_dataset('ptb_text_only', 'penn_treebank', split='test')\n",
        "\n",
        "    trainenc = tokenizer(\" \".join(traindata['sentence']), return_tensors='pt')\n",
        "    testenc = tokenizer(\" \".join(testdata['sentence']), return_tensors='pt')\n",
        "\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in range(nsamples):\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "    return trainloader, testenc\n",
        "\n",
        "import tqdm\n",
        "def get_c4(nsamples, seed, seqlen, model, tokenizer):\n",
        "    traindata = load_dataset(\n",
        "        'allenai/c4', 'allenai--c4', data_files={'train': 'en/c4-train.00000-of-01024.json.gz'}, split='train'\n",
        "    )\n",
        "    valdata = load_dataset(\n",
        "        'allenai/c4', 'allenai--c4', data_files={'validation': 'en/c4-validation.00000-of-00008.json.gz'}, split='validation'\n",
        "    )\n",
        "\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in range(nsamples):\n",
        "        while True:\n",
        "            i = random.randint(0, len(traindata) - 1)\n",
        "            trainenc = tokenizer(traindata[i]['text'], return_tensors='pt')\n",
        "            if trainenc.input_ids.shape[1] > seqlen:\n",
        "                break\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "\n",
        "    valenc = tokenizer(' '.join(valdata[:1100]['text']), return_tensors='pt')\n",
        "    valenc = valenc.input_ids[:, :(256 * seqlen)]\n",
        "\n",
        "    class TokenizerWrapper:\n",
        "        def __init__(self, input_ids):\n",
        "            self.input_ids = input_ids\n",
        "    valenc = TokenizerWrapper(valenc)\n",
        "\n",
        "    return trainloader, valenc\n",
        "\n",
        "\n",
        "def get_generic(nsamples, seed, seqlen, model, tokenizer, dataset_name, train, validation):\n",
        "\n",
        "    traindata = load_dataset(\n",
        "        dataset_name, split=train,\n",
        "    )\n",
        "    valdata = load_dataset(\n",
        "        dataset_name, split=validation,\n",
        "    )\n",
        "    random.seed(seed)\n",
        "    trainloader = []\n",
        "    for _ in tqdm.tqdm(range(nsamples)):\n",
        "        while True:\n",
        "            i = random.randint(0, len(traindata) - 1)\n",
        "            trainenc = tokenizer(traindata[i]['text'], return_tensors='pt')\n",
        "            if trainenc.input_ids.shape[1] > seqlen:\n",
        "                break\n",
        "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = trainenc.input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        trainloader.append((inp, tar))\n",
        "\n",
        "    valenc = tokenizer(' '.join(valdata[:1100]['text']), return_tensors='pt')\n",
        "    valenc = valenc.input_ids[:, :(256 * seqlen)]\n",
        "\n",
        "    class TokenizerWrapper:\n",
        "        def __init__(self, input_ids):\n",
        "            self.input_ids = input_ids\n",
        "    valenc = TokenizerWrapper(valenc)\n",
        "\n",
        "    return trainloader, valenc\n",
        "\n",
        "def get_loaders(name, nsamples=128, seed=0, seqlen=2048, model=''):\n",
        "    tokenizer = get_tokenizer(model)\n",
        "    if 'wikitext2' in name:\n",
        "        return get_wikitext2(nsamples, seed, seqlen, model, tokenizer)\n",
        "    elif 'ptb' in name:\n",
        "        return get_ptb(nsamples, seed, seqlen, model, tokenizer)\n",
        "    elif 'c4' in name:\n",
        "        return get_c4(nsamples, seed, seqlen, model, tokenizer)\n",
        "    else:\n",
        "        name, train, validiation = name.split(\",\")\n",
        "        return get_generic(nsamples, seed, seqlen, model, tokenizer, name, train, validiation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d3oKaq9mos6",
        "outputId": "73dd00ee-7811-472f-be44-8fed7848b424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sparsegpt/llama.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile sparsegpt/llama.py\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from sparsegpt import *\n",
        "from modelutils import *\n",
        "from quant import *\n",
        "\n",
        "try:\n",
        "    import wandb\n",
        "    has_wandb = True\n",
        "except:\n",
        "    has_wandb = False\n",
        "\n",
        "\n",
        "def get_llama(model):\n",
        "    import torch\n",
        "    def skip(*args, **kwargs):\n",
        "        pass\n",
        "    torch.nn.init.kaiming_uniform_ = skip\n",
        "    torch.nn.init.uniform_ = skip\n",
        "    torch.nn.init.normal_ = skip\n",
        "    from transformers import LlamaForCausalLM\n",
        "    model = LlamaForCausalLM.from_pretrained(model, torch_dtype='auto')\n",
        "    model.seqlen = 2048\n",
        "    return model\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def llama_sequential(model, dataloader, dev):\n",
        "    print(\"Starting...\")\n",
        "\n",
        "    use_cache = model.config.use_cache\n",
        "    model.config.use_cache = False\n",
        "    layers = model.model.layers\n",
        "\n",
        "    model.model.embed_tokens = model.model.embed_tokens.to(dev)\n",
        "    model.model.norm = model.model.norm.to(dev)\n",
        "    layers[0] = layers[0].to(dev)\n",
        "\n",
        "    dtype = next(iter(model.parameters())).dtype\n",
        "    inps = torch.zeros(\n",
        "        (args.nsamples, model.seqlen, model.config.hidden_size), dtype=dtype, device=dev\n",
        "    )\n",
        "    cache = {\"i\": 0, \"attention_mask\": None}\n",
        "\n",
        "    class Catcher(nn.Module):\n",
        "        def __init__(self, module):\n",
        "            super().__init__()\n",
        "            self.module = module\n",
        "\n",
        "        def forward(self, inp, **kwargs):\n",
        "            inps[cache[\"i\"]] = inp\n",
        "            cache[\"i\"] += 1\n",
        "            cache[\"attention_mask\"] = kwargs[\"attention_mask\"]\n",
        "            raise ValueError\n",
        "\n",
        "    layers[0] = Catcher(layers[0])\n",
        "    for batch in dataloader:\n",
        "        try:\n",
        "            model(batch[0].to(dev))\n",
        "        except ValueError:\n",
        "            pass\n",
        "    layers[0] = layers[0].module\n",
        "\n",
        "    layers[0] = layers[0].cpu()\n",
        "    model.model.embed_tokens = model.model.embed_tokens.cpu()\n",
        "    model.model.norm = model.model.norm.cpu()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    outs = torch.zeros_like(inps)\n",
        "    attention_mask = cache[\"attention_mask\"]\n",
        "\n",
        "    print(\"Ready.\")\n",
        "\n",
        "    quantizers = {}\n",
        "    for i in range(len(layers)):\n",
        "        layer = layers[i].to(dev)\n",
        "        full = find_layers(layer)\n",
        "\n",
        "        if args.true_sequential:\n",
        "            sequential = [\n",
        "                [\"self_attn.k_proj\", \"self_attn.v_proj\", \"self_attn.q_proj\"],\n",
        "                [\"self_attn.o_proj\"],\n",
        "                [\"mlp.up_proj\", \"mlp.gate_proj\"],\n",
        "                [\"mlp.down_proj\"],\n",
        "            ]\n",
        "        else:\n",
        "            sequential = [list(full.keys())]\n",
        "\n",
        "        for names in sequential:\n",
        "            subset = {n: full[n] for n in names}\n",
        "\n",
        "            gpts = {}\n",
        "            for name in subset:\n",
        "                if (\n",
        "                    not (args.minlayer <= i < args.maxlayer and args.prune_only in name)\n",
        "                ) == (not args.invert):\n",
        "                    continue\n",
        "                gpts[name] = SparseGPT(subset[name])\n",
        "                if args.wbits < 16:\n",
        "                    gpts[name].quantizer = Quantizer()\n",
        "                    gpts[name].quantizer.configure(\n",
        "                        args.wbits, perchannel=True, sym=False, mse=False\n",
        "                    )\n",
        "\n",
        "            def add_batch(name):\n",
        "                def tmp(_, inp, out):\n",
        "                    gpts[name].add_batch(inp[0].data, out.data)\n",
        "\n",
        "                return tmp\n",
        "\n",
        "            handles = []\n",
        "            for name in subset:\n",
        "                handles.append(subset[name].register_forward_hook(add_batch(name)))\n",
        "            for j in range(args.nsamples):\n",
        "                outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask)[0]\n",
        "            for h in handles:\n",
        "                h.remove()\n",
        "\n",
        "            for name in subset:\n",
        "                print(i, name)\n",
        "                print(\"Pruning ...\")\n",
        "                sparsity = args.sparsity\n",
        "                gpts[name].fasterprune(\n",
        "                    sparsity,\n",
        "                    prunen=args.prunen,\n",
        "                    prunem=args.prunem,\n",
        "                    percdamp=args.percdamp,\n",
        "                    blocksize=args.blocksize,\n",
        "                )\n",
        "                gpts[name].free()\n",
        "\n",
        "        for j in range(args.nsamples):\n",
        "            outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask)[0]\n",
        "\n",
        "        layers[i] = layer.cpu()\n",
        "        del layer\n",
        "        del gpts\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        inps, outs = outs, inps\n",
        "\n",
        "    model.config.use_cache = use_cache\n",
        "\n",
        "    return quantizers\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def llama_eval(model, testenc, dev,  dataset: str, log_wandb: bool = False):\n",
        "    print(\"Evaluating ...\")\n",
        "\n",
        "    testenc = testenc.input_ids\n",
        "    nsamples = testenc.numel() // model.seqlen\n",
        "\n",
        "    use_cache = model.config.use_cache\n",
        "    model.config.use_cache = False\n",
        "    layers = model.model.layers\n",
        "\n",
        "    model.model.embed_tokens = model.model.embed_tokens.to(dev)\n",
        "    layers[0] = layers[0].to(dev)\n",
        "\n",
        "    dtype = next(iter(model.parameters())).dtype\n",
        "    inps = torch.zeros(\n",
        "        (nsamples, model.seqlen, model.config.hidden_size), dtype=dtype, device=dev\n",
        "    )\n",
        "    cache = {\"i\": 0, \"attention_mask\": None}\n",
        "\n",
        "    class Catcher(nn.Module):\n",
        "        def __init__(self, module):\n",
        "            super().__init__()\n",
        "            self.module = module\n",
        "\n",
        "        def forward(self, inp, **kwargs):\n",
        "            inps[cache[\"i\"]] = inp\n",
        "            cache[\"i\"] += 1\n",
        "            cache[\"attention_mask\"] = kwargs[\"attention_mask\"]\n",
        "            raise ValueError\n",
        "\n",
        "    layers[0] = Catcher(layers[0])\n",
        "    for i in range(nsamples):\n",
        "        batch = testenc[:, (i * model.seqlen) : ((i + 1) * model.seqlen)].to(dev)\n",
        "        try:\n",
        "            model(batch)\n",
        "        except ValueError:\n",
        "            pass\n",
        "    layers[0] = layers[0].module\n",
        "\n",
        "    layers[0] = layers[0].cpu()\n",
        "    model.model.embed_tokens = model.model.embed_tokens.cpu()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    outs = torch.zeros_like(inps)\n",
        "    attention_mask = cache[\"attention_mask\"]\n",
        "\n",
        "    for i in range(len(layers)):\n",
        "        print(i)\n",
        "        layer = layers[i].to(dev)\n",
        "\n",
        "        if args.gmp:\n",
        "            subset = find_layers(layer)\n",
        "            for name in subset:\n",
        "                W = subset[name].weight.data\n",
        "                thresh = torch.sort(torch.abs(W.flatten()))[0][\n",
        "                    int(W.numel() * args.sparsity)\n",
        "                ]\n",
        "                W.data[torch.abs(W.data) <= thresh] = 0\n",
        "\n",
        "        for j in range(nsamples):\n",
        "            outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask)[0]\n",
        "        layers[i] = layer.cpu()\n",
        "        del layer\n",
        "        torch.cuda.empty_cache()\n",
        "        inps, outs = outs, inps\n",
        "\n",
        "    if model.model.norm is not None:\n",
        "        model.model.norm = model.model.norm.to(dev)\n",
        "    model.lm_head = model.lm_head.to(dev)\n",
        "\n",
        "    testenc = testenc.to(dev)\n",
        "    nlls = []\n",
        "    for i in range(nsamples):\n",
        "        hidden_states = inps[i].unsqueeze(0)\n",
        "        if model.model.norm is not None:\n",
        "            hidden_states = model.model.norm(hidden_states)\n",
        "        lm_logits = model.lm_head(hidden_states)\n",
        "        shift_logits = lm_logits[:, :-1, :].contiguous()\n",
        "        shift_labels = testenc[:, (i * model.seqlen) : ((i + 1) * model.seqlen)][:, 1:]\n",
        "        loss_fct = nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(\n",
        "            shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1)\n",
        "        )\n",
        "        neg_log_likelihood = loss.float() * model.seqlen\n",
        "        nlls.append(neg_log_likelihood)\n",
        "    ppl = torch.exp(torch.stack(nlls).sum() / (nsamples * model.seqlen))\n",
        "    print(f\"Perplexity: {ppl.item():3f}\")\n",
        "    if log_wandb:\n",
        "        wandb.log({f\"{dataset}/perplexity\": ppl.item()})\n",
        "\n",
        "    model.config.use_cache = use_cache\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "    from datautils import *\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"model\", type=str, help=\"LlaMA model to load\")\n",
        "    parser.add_argument(\n",
        "        \"dataset\",\n",
        "        type=str,\n",
        "        #choices=[\"wikitext2\", \"ptb\", \"c4\"],\n",
        "        help=\"Where to extract calibration data from.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--seed\", type=int, default=0, help=\"Seed for sampling the calibration data.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--nsamples\", type=int, default=128, help=\"Number of calibration data samples.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--percdamp\",\n",
        "        type=float,\n",
        "        default=0.01,\n",
        "        help=\"Percent of the average Hessian diagonal to use for dampening.\",\n",
        "    )\n",
        "    parser.add_argument(\"--sparsity\", type=float, default=0, help=\"Target sparsity\")\n",
        "    parser.add_argument(\"--prunen\", type=int, default=0, help=\"N for N:M pruning.\")\n",
        "    parser.add_argument(\"--prunem\", type=int, default=0, help=\"M for N:M pruning.\")\n",
        "    parser.add_argument(\n",
        "        \"--blocksize\",\n",
        "        type=int,\n",
        "        default=128,\n",
        "        help=\"Blocksize to use for adaptive mask selection.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gmp\", action=\"store_true\", help=\"Whether to run the GMP baseline.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--wbits\", type=int, default=16, help=\"Whether to quantize as well.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--minlayer\", type=int, default=-1, help=\"Prune all layers with id >= this.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--maxlayer\", type=int, default=1000, help=\"Prune all layers with id < this.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--prune_only\",\n",
        "        type=str,\n",
        "        default=\"\",\n",
        "        help=\"Prune only layers that contain this text.\",\n",
        "    )\n",
        "    parser.add_argument(\"--invert\", action=\"store_true\", help=\"Invert subset.\")\n",
        "    parser.add_argument(\"--save\", type=str, default=\"\", help=\"Path to saved model.\")\n",
        "    parser.add_argument(\n",
        "        \"--true-sequential\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to run in true sequential model.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--log_wandb\", action=\"store_true\", help=\"Whether to log to wandb.\"\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # init W&B logging\n",
        "    if args.log_wandb:\n",
        "        assert has_wandb, \"wandb not installed try `pip install wandb`\"\n",
        "        wandb.init(config=args)\n",
        "\n",
        "    model = get_llama(args.model)\n",
        "    model.eval()\n",
        "\n",
        "    dataloader, testloader = get_loaders(\n",
        "        args.dataset, nsamples=args.nsamples, seed=args.seed, model=args.model, seqlen=model.seqlen\n",
        "    )\n",
        "\n",
        "    if (args.sparsity or args.prunen) and not args.gmp:\n",
        "        tick = time.time()\n",
        "        llama_sequential(model, dataloader, DEV)\n",
        "        for n, p in model.named_parameters():\n",
        "            print(n, torch.mean((p == 0).float()))\n",
        "            if 'down_proj' in n:\n",
        "                break\n",
        "        print(time.time() - tick)\n",
        "\n",
        "    for dataset in [\"wikitext2\", \"ptb\", \"c4\"]:\n",
        "        dataloader, testloader = get_loaders(\n",
        "            dataset, seed=args.seed, model=args.model, seqlen=model.seqlen\n",
        "        )\n",
        "        print(\"Dataset:\", dataset)\n",
        "        llama_eval(model, testloader, DEV, dataset, args.log_wandb)\n",
        "\n",
        "    if args.save:\n",
        "        model.save_pretrained(args.save)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G29jkwCtqmEe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LoraLinear(nn.Linear):\n",
        "  def __init__(self, in_features, out_features, bias, linear, lora):\n",
        "    super().__init__(in_features, out_features, bias)\n",
        "    self.weight.data = linear.weight.data\n",
        "    if bias:\n",
        "      self.bias.data = linear.bias.data\n",
        "    self.lora = lora\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    #print(f\"input_tensor.shape = {input_tensor.shape}\")\n",
        "    out = super().forward(input_tensor)\n",
        "    #print(f\"out.shape = {out.shape} , self.lora(input_tensor).shape = {self.lora(input_tensor).shape}\")\n",
        "    out = (out + self.lora(input_tensor))/2.0\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Az9-G-otqyuQ"
      },
      "outputs": [],
      "source": [
        "def create_factorized_compression_for_linear(source_linear, rank=None, rank_factor=0.3,  dtype=torch.float32):\n",
        "    with torch.no_grad():\n",
        "      if rank is None:\n",
        "        rank = max(1, int(min(source_linear.weight.shape)*rank_factor))\n",
        "      if hasattr(source_linear, 'bias'):\n",
        "        bias = source_linear.bias\n",
        "      else:\n",
        "        bias = None\n",
        "      source_linear = source_linear.weight.data\n",
        "      device=source_linear.device\n",
        "      assert rank < min(source_linear.shape)\n",
        "      source_linear = source_linear.float()\n",
        "      U, S, Vh = torch.linalg.svd(source_linear)\n",
        "      U = U[:, :rank]\n",
        "      S = S[:rank]\n",
        "      U = U @ torch.diag(S)\n",
        "      Vh = Vh[:rank, :]\n",
        "      U_flatten = U.flatten()\n",
        "      Vh_flatten = Vh.flatten()\n",
        "      max_quant_size = 2^23\n",
        "      #print (\"ranked\")\n",
        "      if len(U_flatten) + len(Vh_flatten) >= max_quant_size:\n",
        "        dist2 = U_flatten[:min(len(U_flatten), max_quant_size)]\n",
        "        dist3 = Vh_flatten[:min(len(Vh_flatten), max_quant_size)]\n",
        "        hi_val = max(torch.quantile(dist3, 1), torch.quantile(dist2, 1))\n",
        "      else:\n",
        "        dist = torch.cat([U_flatten, Vh_flatten])\n",
        "        hi_val = torch.quantile(dist, 1)\n",
        "      low_val = -hi_val\n",
        "      #print (\"quantile\")\n",
        "      U = U.clamp(low_val, hi_val)\n",
        "      Vh = Vh.clamp(low_val, hi_val)\n",
        "      #print (\"clammped\")\n",
        "      print(f\"U.shape = {U.shape}\")\n",
        "      print(f\"Vh.shape = {Vh.shape}\")\n",
        "\n",
        "      lora_down = nn.Linear(Vh.shape[1], Vh.shape[0], dtype=dtype, bias=False, device=source_linear.device)\n",
        "      lora_up = nn.Linear(U.shape[1], U.shape[0], dtype=dtype, bias=bias is not None, device=source_linear.device)\n",
        "      #print (\"Set up linear\")\n",
        "      lora_up.weight.data = U.to(device=device, dtype=dtype)\n",
        "      lora_down.weight.data = Vh.to(device=device, dtype=dtype)\n",
        "      if bias is not None:\n",
        "        lora_up.bias = nn.Parameter(bias.clone())\n",
        "      return nn.Sequential(lora_down, lora_up)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v01GGPjNqw4B"
      },
      "outputs": [],
      "source": [
        "def lord_decompose(layer, proxy_data, rank):\n",
        "    \"\"\"\n",
        "    Be aware when performing LoRD/AFM on Square Matrices:\n",
        "\n",
        "        In square matrices, input and output dimensions are coupled so compression is more challenging.\n",
        "        The optimal low rank approximation may differ significantly from the original matrix due to the coupling.\n",
        "        Square matrices have less intrinsic redundancy between inputs and outputs to exploit.\n",
        "        Decomposing square matrices risks distorting dimensions that interact in complex ways.\n",
        "        The approximation error of AFM tends to be lowest for tall matrices and highest for square ones.\n",
        "        For square matrices, it can help to decompose blocks of interactions rather than the whole matrix.\n",
        "\n",
        "    Paper reference:\n",
        "        Low Rank Decomposition Of Monolingual Code LLMs For One-Shot Compression\n",
        "        ( http://arxiv.org/abs/2309.14021 )\n",
        "\n",
        "    Credit: AI chatbot\n",
        "    \"\"\"\n",
        "\n",
        "    y = layer(proxy_data) # Forward proxy data\n",
        "\n",
        "    cov_y = torch.cov(y.T) # Compute output covariance\n",
        "    cov_y = cov_y.float()\n",
        "\n",
        "    # The matrix to be eigendecomposed is symmetric,\n",
        "    # so we can use torch.linalg.eigh instead of torch.linalg.eig\n",
        "    # We shouldn't get imaginary part.\n",
        "    eigenvalues, eigenvectors = torch.linalg.eigh(cov_y)\n",
        "\n",
        "    # Take top rank eigenvectors in descending order\n",
        "    # selects the last rank indices, which correspond to the largest rank values.\n",
        "    top_idx = torch.argsort(eigenvalues, descending=True)\n",
        "    U = eigenvectors[:, top_idx]\n",
        "\n",
        "    # Convert layer weight to complex before decomposition, needed if using torch.linalg.eig()\n",
        "    #layer.weight = nn.Parameter(layer.weight.to(torch.complex64))\n",
        "    layer.weight = nn.Parameter(layer.weight.to(torch.float32))\n",
        "\n",
        "    # Decompose\n",
        "    w1 = U.T @ layer.weight\n",
        "    w2 = U\n",
        "    #print(f\"w1.shape = {w1.shape}\")\n",
        "    #print(f\"w2.shape = {w2.shape}\")\n",
        "\n",
        "    # Create LoRD layers\n",
        "    lord_up = nn.Linear(w2.shape[1], w2.shape[0])\n",
        "    lord_down = nn.Linear(w1.shape[1], w1.shape[0])\n",
        "\n",
        "    lord_up.weight.data = w2\n",
        "    lord_down.weight.data = w1\n",
        "    #lord_up.weight.data = torch.real(torch.abs(w2))\n",
        "    #lord_down.weight.data = torch.real(torch.abs(w1))\n",
        "\n",
        "    return nn.Sequential(lord_down, lord_up)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "0e528557be7e4b6eb0a6ff51fb7d7de1",
            "d2a5146bec5241c1b022fc683bc2c99d",
            "0c78ce95c0c140cfbd5b72e91f68d901",
            "bc9bb2ea636348f181394ebe5a3896a7",
            "01f216935ddb4d52886040bd3c8e5768",
            "44cb120e7c6c4d798cf6e8aed5083f9e",
            "67ac0c2550cc49db8aefc95934d0a75b",
            "70a7eca1ba81479d8c430c5f34904814",
            "98f69990f8fc4ed6a88926f8d4a70c81",
            "ed22df7f50264ea490281a8e0fa6214c",
            "5b2043462b754c80a7605b132f9b853a",
            "f56efff3381b4b9bb9d6c4af07c63bca",
            "32b664d2c8fe4678b23086866145c39b",
            "520a057b56d8443ca44e8de5aeb64228",
            "c81f3c83812241fe8efe139157caf281",
            "9a7846d3715249c3b1d9a685a2733380",
            "811ba7b9895341d4b125f13be477ec5f",
            "85a613cd096f4656afa9b3cee574365d",
            "28995930814f4e778cc987b81c5f9222",
            "4ac00a0ff35b48bfba86b4e31ee46848",
            "57b6f9fdab0c43caae2fe66159d412f2",
            "6f666652c6cd4424a63b55ba3e2e0cb7",
            "57ac1c649e704ce9bfdbdff249f16386",
            "3b404efa7ac441bba621220a316d074f",
            "55e7aeca99664aa9bcfc96c9e97cd922",
            "8d2b9cb5ff484bedb70a67cb4625ca1c",
            "d294fa6a0b894c76bab3747ed90619cb",
            "f49b0091e17748e78a3977847f407b46",
            "3cb6fb4674dd4a19acb82b1819cfea96",
            "7ecd9b8ee7604ebf812b9c689ca08d2b",
            "dcbd723fda324ac29acfaae096d4dda7",
            "ca400f4471cb419b80c0ad875a68b242",
            "39d3c0d2fd7f43029c3f975fb2e57f03",
            "96850923bae34b4e9bf85f474764bb65",
            "47fcc0e0c2784043934573c482ae4016",
            "8c43021fdd974425989688ed2eda4d29",
            "b890f218babd48debbfb737d704c8aa8",
            "4046aaee46784400b5a7b66f6eb779f3",
            "18b2ce64b9a94b6dbd13bb87e2f6d479",
            "1e58672f7d864198adba2e3146a99215",
            "4443957111494d87871ae5c85e13187e",
            "3f2ae2a7c7174764b0a9faef240e7af7",
            "ea746586a9c843c69d4d2b586bfd9f27",
            "3a67af106e964adc8d3fc036e6eae527",
            "6b57d978e5d7429b8b7b53f5453303b3",
            "ee27b804f8b24c6cbba01f463da4c48b",
            "fcfe290adb4042c0942a39db0b647027",
            "9328dc45aecf4be1b6d7baceed6d30a9",
            "965c0517ae3d479d9b3996c966ef0eb1",
            "eadaea4ae1ad43398b77153eee3b4f90",
            "3ac6ba97304b4618946c76aa91cc425a",
            "df1ffea534ba47bea41e35e40c7bfc04",
            "029169fd5e4c4662b8bc1ad7b85d49c8",
            "2e140c5c271746eba5874d38431c32df",
            "11afd5b088114187892fcfe631d4b426"
          ]
        },
        "id": "KRL54Os9tDN_",
        "outputId": "76a61ab5-4839-4ca5-9751-5ec058ff15d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e528557be7e4b6eb0a6ff51fb7d7de1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/911M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f56efff3381b4b9bb9d6c4af07c63bca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57ac1c649e704ce9bfdbdff249f16386"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96850923bae34b4e9bf85f474764bb65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b57d978e5d7429b8b7b53f5453303b3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import Optional, Tuple, Union\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers.models.gpt_neox.configuration_gpt_neox import *\n",
        "\n",
        "\n",
        "model_name = \"EleutherAI/pythia-410m\" #\"EleutherAI/pythia-70m\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, low_cpu_mem_usage=True ).cuda()\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#model.embed_out  = create_factorized_compression_for_linear(model.embed_out, rank_factor=0.9).cuda().to(torch.bfloat16)\n",
        "#model.gpt_neox.embed_in = create_factorized_compression_for_linear(model.gpt_neox.embed_in, rank_factor=0.2).cuda().to(torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qnwVwUyeq-SV"
      },
      "outputs": [],
      "source": [
        "# Generate proxy dataset\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "proxy_texts = [\n",
        "\"The cat sat on the mat.\",\n",
        "\"The quick brown fox jumps over the lazy dog.\",\n",
        "\"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\",\n",
        "\"In my younger and more vulnerable years my father gave me some advice that I've been turning over in my mind ever since.\",\n",
        "\"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.\",\n",
        "\"In a hole in the ground there lived a hobbit.\",\n",
        "\"Happy families are all alike; every unhappy family is unhappy in its own way.\",\n",
        "\"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of light, it was the season of darkness, it was the spring of hope, it was the winter of despair.\",\n",
        "\"I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.\",\n",
        "\"In the beginning God created the heaven and the earth.\",\n",
        "\"To be, or not to be: that is the question.\",\n",
        "\"Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\",\n",
        "\"We hold these truths to be self-evident, that all men are created equal, that they are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.\",\n",
        "\"I only know that while I am asleep and you are awake, we are fine.\",\n",
        "\"The Answer to the Great Question Of...Life, the Universe and Everything...Is...Forty-two,' said Deep Thought, with infinite majesty and calm.\",\n",
        "\"Not all those who wander are lost.\",\n",
        "\"I took a deep breath and listened to the old brag of my heart. I am, I am, I am.\",\n",
        "\"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
        "\"Don't cry because it's over, smile because it happened.\",\n",
        "\"You have brains in your head. You have feet in your shoes. You can steer yourself any direction you choose.\",\n",
        "\"Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!\",\n",
        "\"Everything you can imagine is real.\",\n",
        "\"We accept the love we think we deserve.\",\n",
        "\"May the odds be ever in your favor.\",\n",
        "\"Keep your face always toward the sunshine - and shadows will fall behind you.\",\n",
        "\"Be kind whenever possible. It is always possible.\",\n",
        "\"Darkness cannot drive out darkness: only light can do that. Hate cannot drive out hate: only love can do that.\",\n",
        "\"Don't walk behind me; I may not lead. Don't walk in front of me; I may not follow. Just walk beside me and be my friend.\",\n",
        "\"You've gotta dance like there's nobody watching, love like you'll never be hurt, sing like there's nobody listening, and live like it's heaven on earth.\",\n",
        "\"You know you're in love when you can't fall asleep because reality is finally better than your dreams.\",\n",
        "\"Being deeply loved by someone gives you strength, while loving someone deeply gives you courage.\",\n",
        "\"It matters not what someone is born, but what they grow to be.\",\n",
        "\"Love looks not with the eyes, but with the mind.\",\n",
        "\"We are what we repeatedly do. Excellence, then, is not an act, but a habit.\",\n",
        "\"The mind is everything. What you think you become.\",\n",
        "\"Simplicity is the ultimate sophistication.\",\n",
        "\"Whatever you do, do it well.\",\n",
        "\"What we think, we become.\",\n",
        "\"Change will not come if we wait for some other person or some other time. We are the ones we've been waiting for. We are the change that we seek.\",\n",
        "\"The question isn't who is going to let me; it's who is going to stop me.\",\n",
        "\"The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart.\",\n",
        "\"It's no use going back to yesterday, because I was a different person then.\",\n",
        "\"Logic will get you from A to Z; imagination will get you everywhere.\",\n",
        "\"One small step for man, one giant leap for mankind.\",\n",
        "\"Either write something worth reading or do something worth writing.\",\n",
        "\"You can never cross the ocean until you have the courage to lose sight of the shore.\",\n",
        "\"A room without books is like a body without a soul.\",\n",
        "\"You only live once, but if you do it right, once is enough.\",\n",
        "\"Be who you are and say what you feel, because those who mind don't matter and those who matter don't mind.\",\n",
        "\"Everybody is a genius. But if you judge a fish by its ability to climb a tree, it will live its whole life believing that it is stupid.\",\n",
        "\"Do what you can, with what you have, where you are.\",\n",
        "\"Do not go where the path may lead, go instead where there is no path and leave a trail.\",\n",
        "\"There is no greater agony than bearing an untold story inside you.\",\n",
        "\"If you want to make peace with your enemy, you have to work with your enemy. Then he becomes your partner.\",\n",
        "\"I have always imagined that Paradise will be a kind of library.\",\n",
        "\"I am no bird; and no net ensnares me: I am a free human being with an independent will.\",\n",
        "\"Beware; for I am fearless, and therefore powerful.\",\n",
        "\"The truth is, everyone is going to hurt you. You just got to find the ones worth suffering for.\",\n",
        "\"Not all those who wander are lost.\",\n",
        "\"I am the wisest man alive, for I know one thing, and that is that I know nothing.\",\n",
        "\"It is never too late to be what you might have been.\",\n",
        "\"We must use time wisely and forever realize that the time is always ripe to do right.\",\n",
        "\"Darkness cannot drive out darkness: only light can do that. Hate cannot drive out hate: only love can do that.\",\n",
        "\"The truth is rarely pure and never simple.\",\n",
        "\"The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.\",\n",
        "\"If you hear a voice within you say 'you cannot paint,' then by all means paint and that voice will be silenced.\",\n",
        "\"Act as if what you do makes a difference. It does.\",\n",
        "\"Do what you can, with what you have, where you are.\",\n",
        "\"Happiness can be found, even in the darkest of times, if one only remembers to turn on the light.\",\n",
        "\"The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart.\",\n",
        "\"The opposite of love is not hate, it's indifference.\",\n",
        "\"Always do what is right. It will gratify half of mankind and astound the other.\",\n",
        "\"Tell the truth, work hard, and come to dinner on time.\",\n",
        "\"Courage is found in unlikely places.\",\n",
        "\"The truth is you don't know what is going to happen tomorrow. Life is a crazy ride, and nothing is guaranteed.\",\n",
        "\"You never really understand a person until you consider things from his point of view.\",\n",
        "\"Do one thing every day that scares you.\",\n",
        "\"Darkness cannot drive out darkness: only light can do that. Hate cannot drive out hate: only love can do that.\",\n",
        "\"Not all those who wander are lost.\",\n",
        "\"I have not failed. I've just found 10,000 ways that won't work.\",\n",
        "\"Love is that condition in which the happiness of another person is essential to your own.\",\n",
        "\"You are confined only by the walls you build yourself.\",\n",
        "\"The question isn't who is going to let me; it's who is going to stop me.\",\n",
        "\"There is some good in this world, and it's worth fighting for.\",\n",
        "\"Words are, in my not-so-humble opinion, our most inexhaustible source of magic.\",\n",
        "\"It matters not what someone is born, but what they grow to be.\",\n",
        "\"I fear not the man who has practiced 10,000 kicks once, but I fear the man who has practiced one kick 10,000 times.\",\n",
        "\"You have power over your mind, not outside events. Realize this and you will find strength.\",\n",
        "\"Knowing what must be done does away with fear.\",\n",
        "\"Life is really simple, but we insist on making it complicated.\",\n",
        "\"You miss 100% of the shots you don't take.\",\n",
        "\"Life isn't about finding yourself. Life is about creating yourself.\",\n",
        "\"Simplicity is the ultimate sophistication.\",\n",
        "\"In the end, we will remember not the words of our enemies, but the silence of our friends.\",\n",
        "\"Never let the fear of striking out keep you from playing the game.\",\n",
        "\"You can do anything, but not everything.\",\n",
        "\"The truth is, everyone is going to hurt you. You just got to find the ones worth suffering for.\",\n",
        "\"True terror is to wake up one morning and discover that your high school class is running the country.\",\n",
        "\"Remember that happiness is a way of travel, not a destination.\",\n",
        "\"If you can't explain it simply, you don't understand it well enough.\",\n",
        "\"You are never too old to set another goal or to dream a new dream.\",\n",
        "\"Our lives begin to end the day we become silent about things that matter.\",\n",
        "\"I learned that courage was not the absence of fear, but the triumph over it.\",\n",
        "\"You may not control all the events that happen to you, but you can decide not to be reduced by them.\",\n",
        "\"The future belongs to those who believe in the beauty of their dreams.\",\n",
        "\"It is during our darkest moments that we must focus to see the light.\",\n",
        "\"Whoever is happy will make others happy too.\",\n",
        "\"Do not go where the path may lead, go instead where there is no path and leave a trail.\",\n",
        "\"You will face many defeats in life, but never let yourself be defeated.\",\n",
        "\"In the end, it's not the years in your life that count. It's the life in your years.\",\n",
        "\"Life is what happens to us while we are making other plans.\",\n",
        "\"The only impossible journey is the one you never begin.\",\n",
        "\"Your time is limited, so don't waste it living someone else's life.\",\n",
        "\"No one can make you feel inferior without your consent.\",\n",
        "\"What you do makes a difference, and you have to decide what kind of difference you want to make.\",\n",
        "\"The only way to do great work is to love what you do.\",\n",
        "\"If you look at what you have in life, you'll always have more. If you look at what you don't have in life, you'll never have enough.\",\n",
        "\"When one door of happiness closes, another opens; but often we look so long at the closed door that we do not see the one which has been opened for us.\",\n",
        "\"Life isn't about getting and having, it's about giving and being.\",\n",
        "\"Strive not to be a success, but rather to be of value.\",\n",
        "\"The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart.\",\n",
        "\"In the end, we will remember not the words of our enemies, but the silence of our friends.\",\n",
        "\"Not all those who wander are lost.\",\n",
        "\"It does not do to dwell on dreams and forget to live.\",\n",
        "\"To the well-organized mind, death is but the next great adventure.\",\n",
        "\"Of course it is happening inside your head, Harry, but why on earth should that mean that it is not real?\",\n",
        "\"Knowing what must be done does away with fear.\",\n",
        "\"You only live once, but if you do it right, once is enough.\",\n",
        "\"Be the change that you wish to see in the world.\",\n",
        "\"Happiness can be found, even in the darkest of times, if one only remembers to turn on the light.\",\n",
        "\"We are what we repeatedly do. Excellence, then, is not an act, but a habit.\",\n",
        "\"There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.\",\n",
        "\"You have to write the book that wants to be written. And if the book will be too difficult for grown-ups, then you write it for children.\",\n",
        "\"It is never too late to be what you might have been.\",\n",
        "\"A room without books is like a body without a soul.\",\n",
        "\"You've gotta dance like there's nobody watching.\",\n",
        "\"It matters not what someone is born, but what they grow to be.\",\n",
        "\"Don't walk behind me; I may not lead. Don't walk in front of me; I may not follow. Just walk beside me and be my friend.\",\n",
        "\"You know you're in love when you can't fall asleep because reality is finally better than your dreams.\",\n",
        "\"Stay afraid, but do it anyway. What's important is the action. You don't have to wait to be confident. Just do it and eventually the confidence will follow.\",\n",
        "\"Love all, trust a few, do wrong to none.\",\n",
        "\"The truth is rarely pure and never simple.\",\n",
        "\"Be bold. If not you, who else?\",\n",
        "\"We gotta dance our way to freedom.\",\n",
        "\"Don't talk about your problems. Eighty percent of people don't care; the other twenty percent will think you deserve them.\",\n",
        "\"Friendship marks a life even more deeply than love. Love risks degenerating into obsession, friendship is never anything but sharing.\",\n",
        "\"You cannot find peace by avoiding life.\",\n",
        "\"Always forgive your enemies - nothing annoys them so much.\",\n",
        "\"However difficult life may seem, there is always something you can do and succeed at.\",\n",
        "\"Keep love in your heart. A life without it is like a sunless garden when the flowers are dead.\",\n",
        "\"You cannot swim for new horizons until you have courage to lose sight of the shore.\",\n",
        "\"You gain strength, courage, and confidence by every experience in which you really stop to look fear in the face.\",\n",
        "\"I can't give you a sure-fire formula for success, but I can give you a formula for failure: try to please everybody all the time.\",\n",
        "\"The universe is change; our life is what our thoughts make it.\",\n",
        "\"No one is useless in this world who lightens the burdens of another.\",\n",
        "\"Don't let the noise of others' opinions drown out your own inner voice.\",\n",
        "\"Darkness cannot drive out darkness: only light can do that. Hate cannot drive out hate: only love can do that.\",\n",
        "\"Either write something worth reading or do something worth writing about.\"\n",
        "# Add more samples from diverse books, speeches, genres etc.\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QQZuy6HqzQs",
        "outputId": "36ea4956-fb84-4068-c516-2ffb66d79508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(model.gpt_neox.layers) = 24\n",
            "now processing layer [0]\n",
            "now processing layer [2]\n",
            "now processing layer [4]\n",
            "now processing layer [6]\n",
            "now processing layer [8]\n",
            "now processing layer [10]\n",
            "now processing layer [12]\n",
            "now processing layer [14]\n",
            "now processing layer [16]\n",
            "now processing layer [18]\n",
            "now processing layer [20]\n",
            "now processing layer [22]\n"
          ]
        }
      ],
      "source": [
        "USE_LORD = 1\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "if USE_LORD:\n",
        "  rank_factor=0.5\n",
        "\n",
        "  print(f\"len(model.gpt_neox.layers) = {len(model.gpt_neox.layers)}\")\n",
        "\n",
        "  #for layer in model.gpt_neox.layers:\n",
        "  for i in range(0, len(model.gpt_neox.layers), 2):\n",
        "    layer = model.gpt_neox.layers[i]\n",
        "\n",
        "    print(f\"now processing layer [{i}]\")\n",
        "\n",
        "    input_dim = layer.attention.dense.in_features\n",
        "    rank = int(input_dim * rank_factor)\n",
        "\n",
        "    input_dim_4h = layer.mlp.dense_4h_to_h.in_features\n",
        "    rank_4h = int(input_dim_4h * rank_factor)\n",
        "\n",
        "\n",
        "    max_length_dense_h_to_4h = layer.mlp.dense_h_to_4h.in_features # Max sequence length\n",
        "    proxy_data_h = tokenizer(proxy_texts, padding=\"max_length\", truncation=True, max_length=max_length_dense_h_to_4h, return_tensors=\"pt\").to(\"cuda\")\n",
        "    proxy_data_h_bf16 = proxy_data_h['input_ids'].to(torch.bfloat16)\n",
        "\n",
        "    max_length_dense_4h_to_h = layer.mlp.dense_4h_to_h.in_features # Max sequence length\n",
        "    proxy_data_4h = tokenizer(proxy_texts, padding=\"max_length\", truncation=True, max_length=max_length_dense_4h_to_h, return_tensors=\"pt\").to(\"cuda\")\n",
        "    proxy_data_4h_bf16 = proxy_data_4h['input_ids'].to(torch.bfloat16)\n",
        "\n",
        "\n",
        "    layer.attention.dense = LoraLinear(layer.attention.dense.in_features, layer.attention.dense.out_features, layer.attention.dense.bias is not None,  layer.attention.dense, \\\n",
        "                                      lord_decompose(layer.attention.dense, proxy_data_h_bf16, rank)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    #layer.attention.query_key_value = LoraLinear(layer.attention.query_key_value.in_features, layer.attention.query_key_value.out_features, layer.attention.query_key_value.bias is not None, layer.attention.query_key_value, \\\n",
        "    #                                   lord_decompose(layer.attention.query_key_value, proxy_data, rank)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    layer.mlp.dense_h_to_4h = LoraLinear(layer.mlp.dense_h_to_4h.in_features, layer.mlp.dense_h_to_4h.out_features, layer.mlp.dense_h_to_4h.bias is not None, layer.mlp.dense_h_to_4h, \\\n",
        "                                      lord_decompose(layer.mlp.dense_h_to_4h, proxy_data_h_bf16, rank)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    layer.mlp.dense_4h_to_h = LoraLinear(layer.mlp.dense_4h_to_h.in_features, layer.mlp.dense_4h_to_h.out_features, layer.mlp.dense_4h_to_h.bias is not None, layer.mlp.dense_4h_to_h, \\\n",
        "                                      lord_decompose(layer.mlp.dense_4h_to_h, proxy_data_4h_bf16, rank_4h)).cuda().to(torch.bfloat16)\n",
        "\n",
        "else:\n",
        "\n",
        "  #for layer in model.gpt_neox.layers:\n",
        "  for i in range(0, len(model.gpt_neox.layers), 2):\n",
        "    layer = model.gpt_neox.layers[i]\n",
        "\n",
        "    print(f\"now processing layer [{i}]\")\n",
        "\n",
        "    layer.attention.dense = LoraLinear(layer.attention.dense.in_features, layer.attention.dense.out_features, layer.attention.dense.bias is not None,  layer.attention.dense, \\\n",
        "                                      create_factorized_compression_for_linear(layer.attention.dense, rank_factor=0.2)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    #layer.attention.query_key_value = LoraLinear(layer.attention.query_key_value.in_features, layer.attention.query_key_value.out_features, layer.attention.query_key_value.bias is not None, layer.attention.query_key_value, \\\n",
        "    #                                   create_factorized_compression_for_linear(layer.attention.query_key_value, rank_factor=0.5)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    layer.mlp.dense_h_to_4h = LoraLinear(layer.mlp.dense_h_to_4h.in_features, layer.mlp.dense_h_to_4h.out_features, layer.mlp.dense_h_to_4h.bias is not None, layer.mlp.dense_h_to_4h, \\\n",
        "                                      create_factorized_compression_for_linear(layer.mlp.dense_h_to_4h, rank_factor=0.5)).cuda().to(torch.bfloat16)\n",
        "\n",
        "    layer.mlp.dense_4h_to_h = LoraLinear(layer.mlp.dense_4h_to_h.in_features, layer.mlp.dense_4h_to_h.out_features, layer.mlp.dense_4h_to_h.bias is not None, layer.mlp.dense_4h_to_h, \\\n",
        "                                      create_factorized_compression_for_linear(layer.mlp.dense_4h_to_h, rank_factor=0.5)).cuda().to(torch.bfloat16)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(txt, return_tensors=\"pt\").to(\"cuda\")\n",
        "print(f\"input_ids.input_ids.shape = {input_ids.input_ids.shape}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  print(tokenizer.batch_decode(model.generate(**input_ids,  no_repeat_ngram_size=2, repetition_penalty=1.1, min_length=input_ids.input_ids.shape[1]+256, max_new_tokens=512))[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7BxVMUbLp3P",
        "outputId": "806355dc-d4fe-4ee5-bf6f-9818c3a82d85"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids.input_ids.shape = torch.Size([1, 477])\n",
            "Abraham Lincoln (/ˈlɪŋkən/ LINK-ən; February 12, 1809 – April 15, 1865) was an American lawyer, politician, and statesman who served as the 16th president of the United States from 1861 until his assassination in 1865. Lincoln led the Union through the American Civil War to defend the nation as a constitutional union and succeeded in abolishing slavery, bolstering the federal government, and modernizing the U.S. economy.\n",
            "\n",
            "Lincoln was born into poverty in a log cabin in Kentucky and was raised on the frontier, primarily in Indiana. He was self-educated and became a lawyer, Whig Party leader, Illinois state legislator, and U.S. Congressman from Illinois. In 1849, he returned to his successful law practice in Springfield, Illinois. In 1854, he was angered by the Kansas–Nebraska Act, which opened the territories to slavery, and he re-entered politics. He soon became a leader of the new Republican Party. He reached a national audience in the 1858 Senate campaign debates against Stephen A. Douglas. Lincoln ran for president in 1860, sweeping the North to gain victory. Pro-slavery elements in the South viewed his election as a threat to slavery, and Southern states began seceding from the nation. During this time, the newly formed Confederate States of America began seizing federal military bases in the south. Just over one month after Lincoln assumed the presidency, the Confederate States attacked Fort Sumter, a U.S. fort in South Carolina. Following the bombardment, Lincoln mobilized forces to suppress the rebellion and restore the union.\n",
            "\n",
            "\n",
            "Marriage and children\n",
            "\n",
            "Lincoln had pledged in 1846 to serve only one term in the House. Realizing Clay was unlikely to win the presidency, he supported General Zachary Taylor for the Whig nomination in the 1848 presidential election.[85] Taylor won and Lincoln hoped in vain to be appointed Commissioner of the General Land Office.[86] The administration offered to appoint him secretary or governor of the Oregon Territory as consolation.[87] This distant territory was a Democratic stronghold, and acceptance of the post would have disrupted his legal and political career in Illinois, so he declined and resumed his law practice.[88]\n",
            "\n",
            "Lincoln's second child was named Mary, but died before he could marry. After his first son, John, was killed in action during the Civil war, Abraham Lincoln was forced to leave the country and return to Ohio, where he married Mary Todd Hite (1844),[89][90].\n",
            "The family tree of Abraham and Mary Lincoln\n",
            "  \n",
            "He then moved to Springfield in 1850, to become a farmer, while his wife Mary was working at the office of President. They had two sons, James, who was elected to Congress, in 1840, when Abraham was nominated, as Senator, for Illinois,[91], and Abraham, then Governor of Illinois.[92] Abraham later joined the Republican party, becoming a Whigs Party member, before being elected President in 1848.[93] He then left the Democratic party and joined another party that was the Federalists, joining the Republicans in 1830s, forming the National Republican Convention in Chicago, defeating the Democrats, winning the election, with the abolitionist faction, secession of slavery and secessing the republican, ending the civil war in 1748.[94] His daughter Mary died in infancy, aged 1 year, from tuberculosis, on her father's farm, near Springfield. [95][96][97][98][99][100][101][102][103][104][105][106][107][108][109][110][111][112][113][114][115][116][117][118][119][120][121][122][123][124][125][126][127][128][129][130][131][132][133][134][135][136][137][138][139][140][141][142][143][144][145][146][147][148][149][150][151][152][153][154][155][156][157][158][159][160][161][162][163][164][165][166][167][168][169][170][171][172][173][174][175][176][177][178][179][180][181][182][183][184][185][186][187][188][189][190][191][192][193][194][195][196][197][198][199][200][201][202][203][204][205][206][207][208][209][210][211][212][213][214][215][216][217][218][219][220][221][222][223][224][225][226][227][228][\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_orig = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, low_cpu_mem_usage=True ).cuda()\n",
        "print('compression', sum(x.shape[0]*x.shape[1] if len(x.shape) == 2 else x.shape[0] for x in model.parameters())/ sum(x.shape[0]*x.shape[1] if len(x.shape) == 2 else x.shape[0] for x in model_orig.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDVEgPnFRPL9",
        "outputId": "b14979e7-7b93-4b7a-ee5b-91143925da85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compression 1.8385333245754534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n",
        "\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "6ggkiW6pLz--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d1be09c-7cd3-431f-eb7a-8d5d64e3eb73"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 453206016 || all params: 745220096 || trainable%: 60.81505563693226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TFUaGmHxkA5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1110d48-b40a-4d1d-8b36-5e5da4e5f758"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 1024)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (1): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (2): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (3): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (4): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (5): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (6): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (7): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (8): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (9): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (10): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (11): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (12): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (13): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (14): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (15): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (16): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (17): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (18): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (19): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (20): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (21): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (22): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): LoraLinear(\n",
              "            in_features=1024, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): LoraLinear(\n",
              "            in_features=1024, out_features=4096, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (dense_4h_to_h): LoraLinear(\n",
              "            in_features=4096, out_features=1024, bias=True\n",
              "            (lora): Sequential(\n",
              "              (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "      (23): GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_orig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9tpn-OU-Dur",
        "outputId": "f8641683-0a96-438e-f09d-20866256a683"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 1024)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e528557be7e4b6eb0a6ff51fb7d7de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2a5146bec5241c1b022fc683bc2c99d",
              "IPY_MODEL_0c78ce95c0c140cfbd5b72e91f68d901",
              "IPY_MODEL_bc9bb2ea636348f181394ebe5a3896a7"
            ],
            "layout": "IPY_MODEL_01f216935ddb4d52886040bd3c8e5768"
          }
        },
        "d2a5146bec5241c1b022fc683bc2c99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44cb120e7c6c4d798cf6e8aed5083f9e",
            "placeholder": "​",
            "style": "IPY_MODEL_67ac0c2550cc49db8aefc95934d0a75b",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "0c78ce95c0c140cfbd5b72e91f68d901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70a7eca1ba81479d8c430c5f34904814",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98f69990f8fc4ed6a88926f8d4a70c81",
            "value": 570
          }
        },
        "bc9bb2ea636348f181394ebe5a3896a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed22df7f50264ea490281a8e0fa6214c",
            "placeholder": "​",
            "style": "IPY_MODEL_5b2043462b754c80a7605b132f9b853a",
            "value": " 570/570 [00:00&lt;00:00, 36.3kB/s]"
          }
        },
        "01f216935ddb4d52886040bd3c8e5768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44cb120e7c6c4d798cf6e8aed5083f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ac0c2550cc49db8aefc95934d0a75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70a7eca1ba81479d8c430c5f34904814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f69990f8fc4ed6a88926f8d4a70c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed22df7f50264ea490281a8e0fa6214c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b2043462b754c80a7605b132f9b853a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f56efff3381b4b9bb9d6c4af07c63bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32b664d2c8fe4678b23086866145c39b",
              "IPY_MODEL_520a057b56d8443ca44e8de5aeb64228",
              "IPY_MODEL_c81f3c83812241fe8efe139157caf281"
            ],
            "layout": "IPY_MODEL_9a7846d3715249c3b1d9a685a2733380"
          }
        },
        "32b664d2c8fe4678b23086866145c39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811ba7b9895341d4b125f13be477ec5f",
            "placeholder": "​",
            "style": "IPY_MODEL_85a613cd096f4656afa9b3cee574365d",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "520a057b56d8443ca44e8de5aeb64228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28995930814f4e778cc987b81c5f9222",
            "max": 911373632,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ac00a0ff35b48bfba86b4e31ee46848",
            "value": 911373632
          }
        },
        "c81f3c83812241fe8efe139157caf281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57b6f9fdab0c43caae2fe66159d412f2",
            "placeholder": "​",
            "style": "IPY_MODEL_6f666652c6cd4424a63b55ba3e2e0cb7",
            "value": " 911M/911M [00:05&lt;00:00, 141MB/s]"
          }
        },
        "9a7846d3715249c3b1d9a685a2733380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811ba7b9895341d4b125f13be477ec5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a613cd096f4656afa9b3cee574365d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28995930814f4e778cc987b81c5f9222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac00a0ff35b48bfba86b4e31ee46848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57b6f9fdab0c43caae2fe66159d412f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f666652c6cd4424a63b55ba3e2e0cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57ac1c649e704ce9bfdbdff249f16386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b404efa7ac441bba621220a316d074f",
              "IPY_MODEL_55e7aeca99664aa9bcfc96c9e97cd922",
              "IPY_MODEL_8d2b9cb5ff484bedb70a67cb4625ca1c"
            ],
            "layout": "IPY_MODEL_d294fa6a0b894c76bab3747ed90619cb"
          }
        },
        "3b404efa7ac441bba621220a316d074f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49b0091e17748e78a3977847f407b46",
            "placeholder": "​",
            "style": "IPY_MODEL_3cb6fb4674dd4a19acb82b1819cfea96",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "55e7aeca99664aa9bcfc96c9e97cd922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ecd9b8ee7604ebf812b9c689ca08d2b",
            "max": 396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcbd723fda324ac29acfaae096d4dda7",
            "value": 396
          }
        },
        "8d2b9cb5ff484bedb70a67cb4625ca1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca400f4471cb419b80c0ad875a68b242",
            "placeholder": "​",
            "style": "IPY_MODEL_39d3c0d2fd7f43029c3f975fb2e57f03",
            "value": " 396/396 [00:00&lt;00:00, 12.2kB/s]"
          }
        },
        "d294fa6a0b894c76bab3747ed90619cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49b0091e17748e78a3977847f407b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb6fb4674dd4a19acb82b1819cfea96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ecd9b8ee7604ebf812b9c689ca08d2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcbd723fda324ac29acfaae096d4dda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca400f4471cb419b80c0ad875a68b242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39d3c0d2fd7f43029c3f975fb2e57f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96850923bae34b4e9bf85f474764bb65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47fcc0e0c2784043934573c482ae4016",
              "IPY_MODEL_8c43021fdd974425989688ed2eda4d29",
              "IPY_MODEL_b890f218babd48debbfb737d704c8aa8"
            ],
            "layout": "IPY_MODEL_4046aaee46784400b5a7b66f6eb779f3"
          }
        },
        "47fcc0e0c2784043934573c482ae4016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b2ce64b9a94b6dbd13bb87e2f6d479",
            "placeholder": "​",
            "style": "IPY_MODEL_1e58672f7d864198adba2e3146a99215",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "8c43021fdd974425989688ed2eda4d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4443957111494d87871ae5c85e13187e",
            "max": 2113710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f2ae2a7c7174764b0a9faef240e7af7",
            "value": 2113710
          }
        },
        "b890f218babd48debbfb737d704c8aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea746586a9c843c69d4d2b586bfd9f27",
            "placeholder": "​",
            "style": "IPY_MODEL_3a67af106e964adc8d3fc036e6eae527",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 8.12MB/s]"
          }
        },
        "4046aaee46784400b5a7b66f6eb779f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b2ce64b9a94b6dbd13bb87e2f6d479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e58672f7d864198adba2e3146a99215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4443957111494d87871ae5c85e13187e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2ae2a7c7174764b0a9faef240e7af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea746586a9c843c69d4d2b586bfd9f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a67af106e964adc8d3fc036e6eae527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b57d978e5d7429b8b7b53f5453303b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee27b804f8b24c6cbba01f463da4c48b",
              "IPY_MODEL_fcfe290adb4042c0942a39db0b647027",
              "IPY_MODEL_9328dc45aecf4be1b6d7baceed6d30a9"
            ],
            "layout": "IPY_MODEL_965c0517ae3d479d9b3996c966ef0eb1"
          }
        },
        "ee27b804f8b24c6cbba01f463da4c48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eadaea4ae1ad43398b77153eee3b4f90",
            "placeholder": "​",
            "style": "IPY_MODEL_3ac6ba97304b4618946c76aa91cc425a",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "fcfe290adb4042c0942a39db0b647027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df1ffea534ba47bea41e35e40c7bfc04",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_029169fd5e4c4662b8bc1ad7b85d49c8",
            "value": 99
          }
        },
        "9328dc45aecf4be1b6d7baceed6d30a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e140c5c271746eba5874d38431c32df",
            "placeholder": "​",
            "style": "IPY_MODEL_11afd5b088114187892fcfe631d4b426",
            "value": " 99.0/99.0 [00:00&lt;00:00, 1.57kB/s]"
          }
        },
        "965c0517ae3d479d9b3996c966ef0eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eadaea4ae1ad43398b77153eee3b4f90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac6ba97304b4618946c76aa91cc425a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df1ffea534ba47bea41e35e40c7bfc04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029169fd5e4c4662b8bc1ad7b85d49c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e140c5c271746eba5874d38431c32df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11afd5b088114187892fcfe631d4b426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
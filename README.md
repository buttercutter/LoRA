# LoRA
LoRA: Low-Rank Adaptation of Large Language Models 

Note:
- Added [LORD: Low Rank Decomposition Of Monolingual Code LLMs For One-Shot Compression](http://arxiv.org/abs/2309.14021) in `lora_decompose()`

TODO:
- MoLoRA (Mixture of Experts for LoRA)

Credit: AI chatbot, [@Ayush Kaushal](https://github.com/Ayushk4), [@ontocord](https://github.com/ontocord/) , [@cloneofsimo](https://github.com/cloneofsimo/)
